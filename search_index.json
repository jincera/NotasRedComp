[["index.html", "Redes de Computadoras Presentación", " Redes de Computadoras José Incera Junio, 2023 Presentación Este documento contiene el material de apoyo para el curso de Redes de Computadoras que se imparte en el Instituto Tecnológico Autónomo de México. La estructuración del material sigue un modelo ascendente, de la capa física a la capa de aplicación, común en libros de texto clásicos de redes de computadoras. El material ha sido integrado a lo largo de varios años de impartir estas materias en los niveles de licenciatura, maestría y diplomado. En él han participado varios profesores, entre los que cabe destacar: Dr. Uciel Fragoso, Dr. Federico Kuhlmann, Dr. José A. Incera, Dr. Marcelo Mejía y M.T. Ramón Ríos. Este documento ha sido escrito en R-Markdown empleando el paquete bookdown. Un agradecimiento especial a Isaac Pimentel, quien adaptó la primera versión de estas notas. "],["intro.html", "Capítulo 1 Introducción Resumen 1.1 Conceptos básicos 1.2 Conmutación 1.3 Multiplexaje 1.4 Arquitecturas de red 1.5 Taxonomía 1.6 Problemas", " Capítulo 1 Introducción Resumen La convergencia entre las tecnologías de la información y las comunicaciones es cada vez mayor y las barreras entre ellas se han diluido casi por completo. Con herramientas como el correo electrónico, la mensajería instantánea, los foros de discusión y las plataformas de trabajo colaborativo, hoy en día la computadora es una innegable herramienta de comunicación. Las redes de computadoras son un tipo de sistemas de comunicaciones. Por ello, iniciamos su estudio describiendo los elementos que conforman un sistema de comunicaciones y que están ahí para ofrecer un servicio específico, en nuestro caso, el de interconexión de equipos computacionales. Más adelante se introducen los conceptos de señal como el elemento físico que se propaga a través de las redes de comunicaciones y se presentan las propiedades que pueden ser alteradas en una señal para transportar información. Como en las redes de computadoras esta información es digital, también se introducen los mecanismos para transformar una señal análoga (por ejemplo, la voz) en su formato binario. Un requerimiento fundamental para que las redes sean técnica y económicamente viables, es la capacidad de compartir los canales de comunicación (cables eléctricos, espectro electromagnético, enlaces de fibra óptica). Por ello, es muy importante asimilar los conceptos de conmutación y de multiplexaje. Una vez presentados los conceptos de sistemas de comunicaciones, entramos en el mundo de las redes de computadoras. Interconectar un conjunto de computadoras es un problema sumamente complejo que involucra desde las propiedades físicas de las señales y los canales de comunicación, hasta la representación interna de los datos que utiliza cada fabricante de computadoras, pasando por cómo establecer las trayectorias más apropiadas para enlazar las computadoras. Ello da lugar a arquitecturas o modelos de redes donde el problema de interconexión se divide en tareas concretas, más sencillas. La arquitectura de redes más popular en el ámbito académico, es el modelo de capas OSI (Open Systems Interconnection). Se trata de un modelo de siete capas en el que la capa inferior ofrece un servicio a la capa superior, hasta resolver completamente la complejidad de la interconexión. El modelo OSI también define la terminología común a las redes de computadoras, como protocolo, punto de acceso a servicio, nodo de interconexión, etcétera. Internet también sigue un modelo de capas, pero solo define formalmente tres, y se considera agnóstico a las llamadas capas inferiores, que son las responsables del transporte de datos. Cerramos este capítulo con una breve taxonomía de las redes de computadoras en función de su área de cobertura. 1.1 Conceptos básicos Durante las últimas décadas los campos de la informática y las telecomunicaciones se han fusionado, generando profundos cambios en la tecnología, los productos y las compañías de esta nueva industria combinada [1], llamada Tecnologías de Información y de Comunicaciones TIC. La revolución generada por esta simbiosis ha afectado significativamente el tejido económico y social del mundo. Las redes digitales se están convirtiendo en el sistema nervioso de la Sociedad de la Información. Para Castells [2], La Red significa nuevas formas de organización que reemplazan jerarquías verticales integradas como la manera dominante de organización social. De acuerdo a la Unión Internacional de Telecomunicaciones (UIT, International Telecommunications Union) el desarrollo dentro del sector de las TIC, puede ilustrarse en tres fases u olas de cambios tecnológicos [3]: La primera ola Está caracterizada por profundos cambios tecnológicos que dieron lugar a la digitalización, la computarización y la aparición de las redes de conmutación de paquetes, conceptos que serán tratados más adelante. Con esta primera ola se consiguió una mejora en la utilización de los recursos y un incremento en la capacidad de las redes de comunicación. Esto posibilitó la creación de nuevos servicios y cimentó un entorno de sinergia que aceleró el desarrollo tecnológico. Al convertir todo tipo de fuente de información en un patrón binario (o digital), la digitalización posibilita la integración de diferentes servicios en la misma red, mejorando sus prestaciones a través de procesos como la compresión, la modularización y la detección y corrección anticipada de errores (FEC, Forward Error Correction). Con las fuentes de información digitalizadas, éstas pueden ser manipuladas automáticamente con programas informáticos. Esta computarización puede ocurrir dentro de la red misma, dotando de inteligencia a los nodos encargados de encaminar la información de un usuario a otro de la red. Como se mostrará más adelante, esta capacidad de procesamiento en los nodos es la base de las redes de conmutación de paquetes, caracterizadas por un uso sumamente eficiente de los recursos disponibles. Esta técnica de conmutación ha sido utilizada en prácticamente todas las arquitecturas de red para transferencia de datos incluyendo, desde luego, aquellas basadas en los protocolos TCP/IP, notablemente la Internet. La segunda ola Es representada por el crecimiento explosivo de las redes de comunicaciones, en especial la telefonía móvil, y la creciente penetración de Internet en la sociedad. Resulta natural que todas estas redes converjan y se complementen entre sí, como de hecho está ocurriendo: En la actualidad, las redes móviles son la principal tecnología de acceso a Internet, mientras que las redes llamadas de cuarta generación (basadas en LTE, Long Term Evolution) son redes de conmutación de paquetes en las que las comunicaciones de voz son sólo un servicio más dentro de todos los que se espera sean ofrecidos por estas redes. Todo lo anterior ha llevado a la llamada convergencia digital la cual está ocurriendo en diferentes niveles [4]: En el nivel de contenidos, por ejemplo, con la aparición de los servicios de Video en Demanda (Video on Demand) y la televisión sobre el protocolo de Internet (IPTV); A nivel de negocios, con esquemas de propiedad cruzada y los servicios triple-play (datos, voz y video) ofrecidos por operadores de telecomunicaciones; A nivel de red con la aparición de redes unificadas para la transmisión de señales; A nivel de dispositivos, con dispositivos de propósito múltiple La tercera ola Va mucho más allá de los desarrollos tecnológicos (y del alcance de este curso), y consiste en el desarrollo de servicios, aplicaciones, contenidos y procesos de apropiación que permitan transitar de una sociedad que usa las TIC, pasando por una sociedad capaz de generar información apoyada en ellas, hacia una sociedad basada en el conocimiento. Así, las redes de comunicaciones son vitales para las sociedades contemporáneas, y es por ello que resulta conveniente entender con claridad los fundamentos técnicos en que se sustentan. 1.1.1 Sistemas de comunicaciones Etimológicamente, la palabra telecomunicación está formada por el prefijo griego tele que significa a distancia y la raíz latina comunicare, hacer común. Así, las telecomunicaciones representan el acto de hacer común, de compartir algo entre dos o más entidades que se encuentran físicamente separadas. Para llevar esta definición a ejemplos concretos, ese algo es información (o conocimiento) que puede ser expresado a través de la voz (tele-fonía), de imágenes (tele-visión) o de símbolos (tele-grafía) y que requiere de un sistema que posibilite esta comunicación a la distancia. En su forma más general, un sistema de comunicaciones está compuesto por los bloques que se ilustran en la figura 1.1: Figura 1.1: Sistema de comunicaciones básico La fuente es la que genera la información y emite mensajes para uno o más destinatarios. La fuente de información puede generar señales analógicas o digitales (ver más adelante). La transferencia de información entre el emisor y el(los) receptor(es), se lleva a través de un canal de comunicación, como puede ser un cable de cobre, una fibra óptica o el espectro radioeléctrico. Cuando las señales viajan a través del canal, necesariamente sufren perturbaciones impredecibles producidas por la naturaleza del canal o por elementos externos al sistema (por ejemplo, atenuaciones debido a la resistividad del medio, interferencia de otras fuentes, distorsión por las propiedades del medio) y que en conjunto se conocen como fuentes de ruido. En el sistema de comunicaciones, el transmisor consiste de un conjunto de elementos (como moduladores, codificadores, amplificadores) que permiten adecuar las señales generadas por las fuentes de información a las condiciones del canal de comunicación y de protegerlas, en la medida de lo posible, de las fuentes de ruido a las que serán sometidas. Al otro extremo del canal, el receptor realiza un proceso inverso para recuperar la señal original y entregarla al destinatario. 1.1.2 Redes de telecomunicaciones Los sistemas de comunicaciones han ido evolucionando y se han convertido hoy en sistemas complejos interconectados por distintos medios para proporcionar un conjunto de servicios. Estos sistemas son las redes de telecomunicaciones y, en términos generales, deben ser capaces de: Proveer un camino entre usuarios y usuarios, y entre usuarios y servicios; posibilitar a cada usuario para que pueda seleccionar a sus destinatarios; proveer servicios con calidad, aún en periodos de gran actividad; proporcionar mecanismos de control y gestión. La posibilidad de una red de procesar y transmitir información del tipo deseado por los usuarios, es el servicio proporcionado por dicha red. Los usuarios pueden ser finales (suscriptores) o intermedios (otras redes). Algunos ejemplos de servicios, son los siguientes: Telefónico local Video transmisión Tránsito Acceso a internet Acceso a red de abonado 1.1.3 Señal Un sistema analógico (o análogo) utiliza una propiedad física, como el voltaje, para representar el comportamiento de otro sistema físico. Las propiedades de esta representación son explotadas para almacenar, transformar, duplicar o amplificar el fenómeno original. Las señales utilizadas en un sistema analógico son continuas, por lo que pueden tomar un número potencialmente infinito de valores. Hay muchos ejemplos de señales analógicas en la naturaleza, como el sonido, la temperatura ambiente o la intensidad de una fuente de luz (por supuesto, sin considerar los procesos que ocurren a nivel de la física cuántica). De forma similar, la altura de una rampa varía de forma continua y su valor en un punto determinado solo puede ser establecida limitando la resolución del dispositivo utilizado para efectuar la medición. Una desventaja de un sistema analógico es la acumulación de pequeñas variaciones aleatorias cada vez que se realiza una operación sobre la señal adquirida. Por ejemplo, en el caso específico de un sistema eléctrico, siempre existen perturbaciones debidas al movimiento molecular (ruido térmico). Por su parte, una señal digital solo puede tomar valores discretos y cuantificables del fenómeno físico. Por ejemplo, el número de árboles en un predio o el de los peldaños en una escalera. Una señal analógica puede ser convertida en una señal digital lo cual, como se mostrará más adelante, ofrece una gran flexibilidad para manipular la señal. A este proceso se le llama digitalización y conviene recordar que la digitalización es uno de los detonadores de la primera ola en el desarrollo de las TIC. Por comodidad vamos a trabajar con señales senoidales simples como la que aparece en la figura 1.2. Como lo demuestra el Teorema de Fourier, cualquier señal periodica puede aproximarse como una suma de funciones senoidales1. Una señal senoidal pura se muestra en la figura 1.2 representada como \\(s(t)\\). Las propiedades de la señal que pueden ser manipuladas para transportar información, son su amplitud (\\(A\\)), su frecuencia (\\(\\omega\\)) y su fase (\\(\\phi\\)). La amplitud es la magnitud máxima que puede tomar la señal. El tiempo que le toma a una señal desplegar una oscilación completa, se conoce como periodo y su inverso es la frecuencia \\(\\omega\\), que indica el número de oscilaciones por segundo que realiza \\(s(t)\\). La frecuencia se mide en Hertz. La separación (medida en grados o radianes) de un punto de referencia arbitrario al inicio de un ciclo, es lo que se conoce como fase y se representa por \\(\\phi\\). Figura 1.2: Señal senoidal. 1.1.4 Conversión analógica a digital (A/D) La representación digital de una señal analógica se construye mediante las tres etapas mostradas en la figura 1.3. El proceso inicia obteniendo muestras de la magnitud de la señal a intervalos regulares (muestreo). A cada muestra obtenida se le asigna el más cercano de un conjunto finito de valores (cuantización). El valor seleccionado se codifica, utilizando típicamente una representación binaria (codificación). Figura 1.3: Proceso de conversión de una señal analógica a digital. La cuantización implica una distorsión de la señal original (llamada error de cuantización) pues, en general, el valor discreto que representa la muestra no coincidirá exactamente con su magnitud en ese punto (ver figura 1.4). En cambio, la señal digital es mucho más inmune a factores externos (las fuentes de ruido de la figura 1.1) que alteran la magnitud de la señal. Figura 1.4: Muestreo y cuantización de una señal analógica. Finalmente, cada muestra cuantizada es representada por un valor binario (figura 1.5). El conjunto de valores utilizados para la representación digital debe elegirse con cuidado. Entre mayor sea el conjunto menor será la separación entre ellos, y por consiguiente, el error de cuantización será menor. Sin embargo, el patrón binario (es decir, el número de bits) para representar estos valores aumenta. Además, disminuye la posibilidad de eliminar el ruido aditivo generado por fuentes externas. Figura 1.5: Codificación de la señal cuantizada. Por simplicidad, en el ejemplo anterior se ha elegido un código de tres bits. Con tres bits, se tienen \\(2^3=8~\\)niveles discretos. Cada magnitud muestreada se aproxima al nivel más cercano de ellos. El proceso de digitalización anterior, en el que cada muestra es convertida al valor discreto más cercano y codificada en una serie de pulsos binarios, también se le conoce como Modulación por Codificación de Pulsos (PCM, Pulse Code Modulation). Teorema de Nyquist Para reconstruir la señal analógica a partir de sus muestras cuantizadas, se recurre a un proceso matemático de interpolación. En 1924, Henry Nyquist mostró, a través del teorema que lleva su nombre, que para obtener una reconstrucción completa, bastaba con tomar muestras al doble de la frecuencia máxima de la señal original2. En consecuencia, es necesario conocer el rango de frecuencias de la señal (es decir, su ancho de banda, determinar la frecuencia más alta y muestrear al doble de este valor para que la señal digital retenga las propiedades de la original. Caso de estudio: Digitalización de voz con calidad comercial Es ilustrativo ejemplificar los conceptos de conversión A/D en el marco de las redes telefónicas digitales. La voz está formada por señales que tienen componentes de frecuencia más allá de los 12,000 Hz. Sin embargo, los componentes principales de la voz, es decir, aquellos que permiten distinguir con claridad el mensaje emitido, se encuentran en el rango de 300 Hz a 3,400 Hz. En las redes telefónicas digitales se transforma la voz en una señal eléctrica que es sensada cada 125 ms, obteniendo 8,000 muestras por segundo, es decir, un poco más del doble requerido por el teorema a de Nyquist. Cada valor se representa con un número binario de 8 bits (se tienen \\(2^8=256\\,\\) niveles discretos), por lo que la señal digital tiene una tasa de \\(8b\\times 8000= 64\\,kb/s\\). Por supuesto, si se comprimen las señales digitalizadas, se requerirá de una tasa de transferencia menor. Si se capturan menos de dos muestras por ciclo (es decir, si se muestrea a menos del doble de la frecuencia máxima), entonces la señal que se generaría a partir de las muestras tomadas, no es la original, sino una en la que se han perdido algunas de sus propiedades. Por ejemplo, en la figura 1.6, los puntos azules se capturan a una tasa notablemente menor a \\(2f_{max}\\), lo que genera la señal representada por la línea azul punteada. Figura 1.6: Efecto de muestreo a una tasa menor a la frecuencia de Nyquist. Si bien la digitalización introduce una cierta complejidad en el tratamiento de la señal original, la representación digital de la información tiene enormes ventajas para poder procesarla (por ejemplo, para comprimirla, transformarla, analizarla mediante programas de cómputo), almacenarla (por ejemplo, en un archivo) y transportarla en sistemas de comunicaciones digitales. Es por ello que en la actualidad, prácticamente todos los sistemas de comunicaciones están convergiendo hacia su digitalización. El teorema de Nyquist, además de indicar el número de muestras necesario para reconstruir una señal analógica a partir de la representación digital, fija el límite máximo de la cantidad de información que puede ser transmitida a través de un canal sin ruido. Si la digitalización se realiza al doble de la frecuencia máxima de la señal original (\\(H\\)) y si se utilizan \\(V\\) niveles discretos, entonces: \\[ \\text{Tasa máxima de datos} = 2H \\log_2 (V)\\,b/s \\] Claude Shannon extiende en 1948 el trabajo original de Nyquist para canales con presencia de ruido [5]. Si la cantidad de ruido en el canal se obtiene a partir de la relación entre la potencia de la señal a trasmitir (\\(S\\)) y la potencia del ruido presente (\\(N\\)), entonces la tasa ideal de un canal con ancho de banda \\(H\\) y relación señal a ruido (SNR, signal to noise ratio) \\(S/N\\) es: \\[ \\text{Tasa máxima de datos} = H \\log_2 (1 + \\frac{S}{N})\\,b/s \\] Este resultado es muy importante porque, además de ofrecer el límite teórico de la capacidad de un canal, indica que cualquier mensaje puede ser transmitido con confiabilidad, a pesar de tener un canal con ruido, diseñando una codificación que mejore la relación señal a ruido [6]. 1.2 Conmutación En términos generales, una red de comunicaciones busca interconectar los equipos terminales (los dispositivos de los usuarios) de la manera más eficiente posible. Resulta impensable asumir una conexión directa de todos los equipos terminales entre sí. Se requiere de canales de comunicación que puedan ser compartidos entre los flujos intercambiados por los equipos terminales, y de mecanismos que permitan esa compartición. Dos de estos mecanismos son la conmutación y el multiplexaje. La conmutación permite establecer una trayectoria entre los equipos terminales que desean comunicarse, a través de la cual se efectuará la transferencia de información. Utiliza dispositivos intermedios llamados conmutadores o switches que habilitan una conexión entre sus puertos. Un ejemplo muy sencillo de una red con un solo conmutador se muestra en la figura 1.7. El dispositivo en azul representa un conmutador que tiene conectadas en sus seis puertos, las computadoras A a F. En la imagen de la izquierda, el conmutador ha establecido una trayectoria entre A y F y entre B y D. En otro momento, la imagen de la derecha muestra trayectorias establecidas entre B y C, y entre D y F. Figura 1.7: Red simple formada por un conmutador y seis equipos terminales El conmutador mantiene una tabla para decidir cómo encaminar la información entre sus puertos (por ejemplo, para interconectar las computadoras A y F en la imagen izquierda de la figura 1.7. Esta tabla puede configurarse de muchas maneras distintas, tales como a través de un mecanismo de señalización o con base en identificadores contenidos en la información; ser estática o cambiar dinámicamente; definir una ruta física o virtual. Una parte sustancial del este curso consiste, precisamente, en conocer en detalle cómo operan distintos mecanismos de conmutación. Históricamente y a un alto nivel, las distintas técnicas de conmutación suelen agruparse en tres categorías: conmutación de mensajes, de circuitos y de paquetes. En la actualidad, la conmutación de mensajes prácticamente ha desaparecido y la conmutación de paquetes va tomando cada vez más relevancia sobre la conmutación de circuitos. 1.2.1 Conmutación de mensajes En la conmutación de mensajes, a la información (es decir, el mensaje) que se desea enviar se le agrega un encabezado con varios campos; los dos más importantes son el identificador (la dirección) del destinatario y del remitente. El mensaje en su totalidad es transmitido de un nodo de interconexión (un conmutador) a otro hasta llegar a su destino. En la figura 1.8, el mensaje está representado por el rectángulo en color rojo y el encabezado, por el azul que lo antecede. El mensaje viaja del emisor al receptor a través de los conmutadores A y B. Figura 1.8: Conmutación de mensajes. La figura 1.8 supone que los nodos de conmutación son de almacenamiento y reenvío, es decir, el mensaje debe llegar en su totalidad al nodo antes de ser reenviado por el puerto de salida que corresponda. Esto permite, entre otras cosas, verificar la integridad del mensaje. Como se verá en un capítulo posterior, también existen nodos de conmutación que empiezan a reenviar la información tan pronto se ha recibido el encabezado. La conmutación de mensajes es muy ineficiente: El enlace entre dos dispositivos (por ejemplo, entre los nodos A y B en la figura 1.8), está ocupado exclusivamente por el mensaje en curso. Si éste es muy grande y otros dispositivos desean enviar información a través del mismo enlace, tendrán que esperar mucho tiempo hasta que el medio se libere. Además, si por alguna razón una parte del mensaje se daña, se tendría que reenviar el mensaje en su totalidad, aunque sólo fueran unos cuantos bits los afectados. Finalmente, si los nodos son de almacenamiento y reenvío, la red en su conjunto está subutilizada, pues no hay información (del mensaje) que pueda fluir entre distintos enlaces al mismo tiempo. Para comprender mejor este punto, en la figura 1.9 el mensaje se ha dividido en distintos fragmentos (llamados paquetes o datagramas). Puede apreciarse que distintos fragmentos viajan simultáneamente por diversos enlaces, reduciendo sustancialmente el tiempo de transmisión entre la fuente y el destino. Figura 1.9: Fragmentación de un mensaje en paquetes En la imagen derecha de la figura 1.9, el mensaje se ha dividido en cinco paquetes. El tamaño del encabezado es artificialmente grande para enfatizar el hecho de que paquetes demasiado pequeños también tienen un impacto negativo en la eficiencia de la red: Los encabezados se deben replicar tantas veces como paquetes haya, gastando recursos y tiempo de transmisión. 1.2.2 Conmutación de circuitos En la conmutación de circuitos se fija una trayectoria (o circuito) entre los equipos terminales y se reservan los recursos necesarios (como capacidad en los enlaces, espacio de memoria y mapa de encaminamiento en los nodos de interconexión) para que la información fluya de la fuente al destino. Ningún otro flujo podrá interrumpir esta comunicación. Si otro equipo terminal requiere del mismo enlace para establecer una nueva trayectoria, la ruta sólo se establece si quedan recursos suficientes; de lo contrario, la solicitud de conexión se bloquea o se rechaza. La conmutación de circuitos tiene las tres fases que se muestran en la figura 1.10: Establecimiento de conexión, intercambio de datos y desconexión. Figura 1.10: Las tres fases de las redes de circuitos conmutados Establecimiento de conexión. Antes de transferir datos, la trayectoria entre fuente y destino debe fijarse. Esta puede establecerse de antemano (para conexiones de larga duración llamadas circuitos permanentes o dedicados) o mediante un proceso de señalización. Por ejemplo, en las redes telefónicas, el mecanismo de descolgar y marcar el número telefónico detona la señalización necesaria para encontrar una ruta hacia el abonado, reservar los recursos necesarios y establecer el circuito que permita que la conversación telefónica se lleve a cabo3. Intercambio de información. Una vez establecida la conexión, el intercambio de información entre los equipos terminales puede llevarse a cabo. En las redes telefónicas, el circuito establecido es bidireccional; en algunas redes de datos debe establecerse un circuito en cada dirección. Desconexión. Cuando se ha terminado de transferir la información que se deseaba intercambiar (o cuando desaparece la necesidad de mantener un circuito dedicado), se activa otro proceso de señalización para desconectar el circuito. Este proceso tiene dos objetivos principales: Notificar a la contraparte que el circuito ya no estará disponible y liberar los recursos de la red para que otros usuarios puedan aprovecharlos. En el ejemplo de las redes telefónicas, al colgar el auricular (o su equivalente en los teléfonos inteligentes) se libera el circuito y los recursos que este ocupaba. En la figura 1.10, el tiempo transcurre de arriba hacia abajo. En el establecimiento de conexión, la señalización pasa de nodo a nodo buscando establecer la trayectoria y reservando los recursos necesarios para el intercambio de información. Cuando se alcanza el destino y éste está dispuesto a aceptar la conexión (por ejemplo, en la red telefónica, al recibir el timbrado de llamada y descolgar el auricular) la señalización necesaria va en sentido inverso. Cuando llega a la fuente, el circuito se ha establecido. Una gran desventaja de las redes de conmutación de circuitos es precisamente el hecho de que los recursos están reservados y dedicados exclusivamente a la conexión establecida, durante el tiempo de vida de la sesión, se utilicen o no. Refiriéndonos una vez más a la red telefónica, una vez que se ha establecido la conexión, el circuito reservado ocupa recursos de la red haya o no intercambio de palabras. La figura 1.11 ejemplifica una red de conmutación de circuitos en la que los equipos terminales son aparatos telefónicos. Se han establecido cuatro circuitos representados por un color distinto: verde, rojo, azul y oro. En la figura, estas conexiones han agotado los recursos disponibles al interior de la red, por lo que únicamente se pueden establecer algunas llamadas adicionales en las que la trayectoria no pase por el núcleo de la red. Por supuesto, este es un escenario irreal. Los enlaces entre nodos de conmutación (llamados troncales), tienen capacidad para establecer muchos circuitos telefónicos, no solamente uno. Figura 1.11: Red de conmutación de circuitos. 1.2.3 Conmutación de paquetes La información que se desea transmitir se divide en bloques llamados paquetes4. Como ya se ha mencionado, a cada paquete se le agrega un encabezado con ayuda del cual los nodos de conmutación podrán encaminar el paquete hacia su destino. Las arquitecturas de redes basadas en conmutación de paquetes se dividen en dos categorías: circuitos virtuales y datagramas. En la primera, al igual que en las redes de conmutación de circuitos, la ruta de la fuente al destino se establece antes de que pueda haber un intercambio de datos. Todos los paquetes de una misma conexión recorren la misma trayectoria, como se muestra en la figura 1.12, en la que las trayectorias entre los equipos terminales (esta vez conformados por computadoras), están representadas por las líneas punteadas de color. Por su parte, los círculos de color ejemplifican los paquetes correspondientes a la información intercambiada en cada conexión. A cada paquete se le agrega un encabezado que permite a los nodos de conmutación identificar a qué trayectoria5 pertenece y, por lo tanto, encaminarlo por el puerto adecuado. Figura 1.12: Red de conmutación de paquetes - Circuitos virtuales. Se les llama circuitos virtuales porque los recursos no son dedicados a una sola conexión, como se observa en la figura en el enlace compartido por los flujos verde y rojo. Esta es la principal ventaja de las redes de conmutación de paquetes: los enlaces, como otros recursos de red, son compartidos por los paquetes de distintas conexiones, lo que aumenta sustancialmente la eficiencia de la red. Sin embargo, ahora los paquetes compiten por los recursos disponibles. Si en un momento dado la información agregada de los paquetes que ingresan a un nodo excede la capacidad del enlace de salida, los paquetes deberán ser encolados en una memoria temporal (un buffer) esperando su turno para ser re-encaminados. A este efecto se le llama congestión. Si la congestión es sostenida, la memoria temporal se satura y los paquetes en exceso deben ser descartados. Algunas arquitecturas de red proveen mecanismos para que, en caso de congestión, paquetes identificados como prioritarios sean reenviados primero, sin tener que esperar (demasiado) en el buffer o correr el riesgo de ser descartados. A estos mecanismos se les llama Calidad de Servicio (QoS, Quality of Service). En la categoría de conmutación de paquetes - datagramas, no se establece una conexión virtual. El encabezado en cada paquete (datagrama) contiene el identificador del emisor y del destinatario (en vez de solamente el identificador de trayectoria). Con esta información, los nodos de conmutación deciden por qué puerto encaminar el paquete para acercarlo a su destino. Para ello, los nodos (más adelante los llamaremos enrutadores) intercambian información entre sí para darse una idea de la topología de la red. La figura 1.13 muestra una red de conmutación de datagramas. En términos generales, cada nodo decide, con la información que tiene en ese momento, cuál es la opción más apropiada para reenviar los datagramas. Por ejemplo, si un enlace se encuentra congestionado, podría decidir encaminar datagramas por rutas alternas como se observa en la figura. Figura 1.13: Red de conmutación de paquetes - Datagramas. Estas arquitecturas son más tolerantes a fallos y a eventos temporales de congestión en la red. En cambio, los paquetes pueden llegar al destino fuera de orden, con alta variabilidad en el retardo entre uno y otro, pueden perderse y, como se verá en capítulos posteriores, hasta pueden duplicarse. Será responsabilidad del receptor reordenarlos y detectar una eventual pérdida o duplicación. Por ello, al encabezado también suele agregársele un número de secuencia junto con otra información de control. En la tabla siguiente se sintetizan algunas características generales de las redes de conmutación de circuitos y de conmutación de paquetes. Conmutación de circuitos Conmutación de paquetes Características Trayectoria con recursos dedicados para el flujo Puede establecerse o no una trayectoria pero los recursos son compartidos Ancho de banda y retardo invariantes Retraso variable en caso de congestión Menor sobrecarga Nodos de almacenamiento y reenvío Apropiadas para flujos a tasa constante Apropiadas para flujos a tasa variable (ráfagas) Paquetes admitidos aún bajo congestión (ligera) Puertos de entrada y salida pueden operar a distinta velocidad Limitaciones Ineficiencia por recursos no aprovechados Sobrecarga de encabezados; complejidad en los nodos Uso típico Redes telefónicas Redes de computadoras Para cerrar esta sección se recomienda ver los siguientes videos: Leonard Kleinrock on packet switching The story of packet switching 1.3 Multiplexaje En la sección anterior se comentó brevemente sobre la importancia de poder compartir los canales de comunicación para poder implementar redes eficientes. El multiplexaje (o multiplexación) se refiere precisamente a la forma en la que flujos de distintas fuentes pueden intercalarse para compartir estos canales de comunicación. Sus orígenes se remontan al finales del siglo XIX en las redes telegráficas; hoy es una técnica sumamente utilizada en todas las redes de telecomunicaciones. El principio de base consiste en que un conjunto de flujos de distintas fuentes utiliza un mismo enlace (canal) de comunicación. La suma promedio de los flujos entrantes (\\(\\lambda_i\\)) es menor que la capacidad del enlace de salida (\\(\\mu\\)); de lo contrario, la red, al menos en el punto de multiplexaje, perdería datos de forma permanente, haciendo inestable al sistema. \\[\\text{Utilización}=\\rho =\\frac{\\Sigma \\lambda_i}{\\mu} &lt; 1\\] Existen muchas formas de multiplexaje; en redes de computadoras, las más importantes son: Multiplexaje en el tiempo (TDM, Time Division Multiplexing) Multiplexaje en frecuencia (FDM, Frequency Division Multiplexing) Multiplexaje por división de código (CDM, Code Division Multiplexing) Multiplexaje en el espacio (SDM, Time Division Multiplexing) 1.3.1 Multiplexaje en el tiempo En TDM, la capacidad del canal se asigna en su totalidad a los flujos de entrada en distintos intervalos de tiempo. La división en intervalos puede ser fija, como se muestra en la figura 1.14, donde las fuentes verde, azul y roja se alternan regularmente la transmisión en el canal de comunicación. El acceso al canal también puede ser dinámico, conforme se generen los flujos de información. En caso de que dos o más fuentes deseen transmitir simultáneamente, se debe contar con algún mecanismo de arbitraje para controlar el acceso (en competencia) al canal. A esta forma de multiplexaje se le conoce como multiplexaje estadístico. El intervalo de tiempo asignado a cada flujo está acotado para que las distintas fuentes no perciban un retraso considerable en su comunicación, derivado del acceso concurrente al canal. Este intervalo puedo tener una duración constante o variable. El multiplexaje TDM se utiliza principalmente para comunicaciones digitales. Cuando a las fuentes de información se les asigna un intervalo fijo con duración constante, requiere de una fuerte sincronización entre ellas. Figura 1.14: Multiplexaje por división de tiempo. Prácticamente todas las redes de telefonía fija son digitales y utilizan TDM para transportar las señales de voz en los enlaces entre centrales telefónicas. La arquitectura de red más popular en la actualidad para ello, es SONET/SDH. 1.3.2 Multiplexaje en frecuencia FDM divide la capacidad del medio en canales más pequeños asignados a las distintas fuentes de información. Una vez asignado un canal, la fuente puede transmitir información durante todo el tiempo (asignado), aunque con capacidad (es decir, tasa de transmisión) limitada, como se muestra en la figura 1.15. La transmisión de los flujos en el canal asignado requiere de un proceso de modulación de una señal llamada portadora para hacer un corrimiento de la señal original hacia la frecuencia del canal correspondiente. Las técnicas de modulación no serán cubiertas en este curso. La asignación de fuentes a canales puede ser fija o dinámica; asimismo, la capacidad de cada canal puede ser constante o variar en función de los requerimientos de los flujos de información. Figura 1.15: Multiplexaje por división de frecuencia. Un ejemplo común aunque no vinculado con redes de computadoras de FDM, es la asignación de distintas frecuencias para las estaciones de radio y televisión al compartir el espectro radioeléctrico. Como se presentará detalladamente en un capítulo posterior, una aplicación más cercana a las redes de interés en este curso, es la configuración de redes WiFi en distintos canales para evitar que las señales se traslapen. Dentro de un canal, se utiliza el multiplexaje por división de código CDM (ver más adelante). Una variante muy importante de FDM para redes ópticas, es el multiplexaje por longitud de onda, WDM (Wave Division Multiplexing), utilizado para que distintas señales puedan viajar simultáneamente por la misma fibra óptica. Cada señal se modula en una longitud de onda distinta. Se considera una variante de FDM pues la longitud de onda (\\(\\lambda\\)) y la frecuencia (\\(f\\)) están directamente relacionadas por la velocidad de la luz (\\(c\\)): \\[\\lambda = \\frac{c}{f}\\] 1.3.3 Multiplexaje por división de código En general, cuando varias señales con niveles de potencia similares son transmitidas al mismo tiempo en el mismo medio, generan tal interferencia entre sí que las señales originales quedan irreconocibles. En cambio, si para una señal determinada, la potencia que percibe de las demás es muy baja, esta interferencia puede ser considerada como ruido y mientras no rebase un umbral, la señal original puede recuperarse. CDM utiliza un medio con ancho de banda mucho mayor al que se requeriría dedicando un canal para transmitir la señal. Ésta se disemina en ese ancho de banda (es una técnica de dispersión de espectro, spread spectrum) con un código tal que sea percibido como ruido de baja potencia para otras señales que están ocupando el medio. Si todas las señales utilizan la misma técnica pero sus códigos de dispersión son ortogonales, es decir, con muy baja probabilidad de que tengan elementos comunes, entonces todas las señales pueden ser recuperadas con muy alta probabilidad. Existen dos formas de espectro disperso: Secuencia directa (DSSS, Direct sequence spread spectrum), que es la más utilizada, y salto de frecuencia (FHSS, frequency hopping spread spectrum). En la primera, la información original se transmite en una serie de pulsos cortos en secuencias llamada chips. El factor de dispersión ortogonal es el número de chips por bit o de bits por símbolo. Es de esperar que otra señal que se transmita simultáneamente por el mismo medio, tendrá un código de chip (un patrón de pulsos, chips por bit, etcétera) distinto para no interferir con las demás. En FHSS, las señales brincan de una frecuencia a otra en intervalos de tiempo cortos llamados chip time. Aunque en la actualidad se utiliza menos que DSSS, se ha elegido esta forma para ejemplificar el funcionamiento de CDM en la figura 1.16 pues es muy sencilla de comprender visualmente. Se puede observar claramente cómo la señal de la fuente verde, por ejemplo, se transmite en un canal durante un chip time y brinca a uno distinto para el siguiente intervalo. Figura 1.16: Multiplexaje por división de código, CDM - Salto de frecuencia (FHSS). El código en este caso, consiste en la duración del intervalo y en las frecuencias (los canales) que la señal utiliza en cada uno de ellos. Cada fuente tendrá su propio código y sólo el receptor que tenga el mismo código podrá recuperar la señal original. Esta característica ofrece una gran seguridad para las comunicaciones que requieran de alta privacidad. De hecho, el espectro disperso fue una técnica desarrollada para proteger comunicaciones militares en los años cincuenta. CDM se utiliza intensamente en la actualidad en muchas redes, como en los sistemas GPS, GSM para telefonía móvil, WiMAX para redes de acceso inalámbricas y en WiFi para el despliegue de redes locales inalámbricas. Conviene enfatizar que en estas últimas, todos los equipos comparten el mismo código de dispersión. CDM se utiliza para compartir el espectro de frecuencia con otros servicios, no para asegurar la privacidad de las distintas comunicaciones. 1.3.4 Multiplexaje espacial En comunicaciones inalámbricas, dado que la potencia de una señal se degrada (en la atmósfera terrestre) exponencialmente con la distancia, una banda de frecuencias (es decir, un canal de comunicaciones inalámbricas) puede ser reutilizada por distintas fuentes de información siempre que éstas se encuentren lo suficientemente alejadas entre sí como para no generar interferencia. Es por ello que, por ejemplo, un mismo canal de radio o televisión puede tener señales distintas en diferentes zonas geográficas del país. Del mismo modo, el multiplexaje espacial permite la reutilización de frecuencias en las células de las redes móviles así como en las zonas de cobertura de redes WiFi. En redes cableadas, también se utiliza (quizás inapropiadamente) el término multiplexaje espacial para describir redes cuya topología está conformada por enlaces punto a punto (es decir, sólo conectan dos dispositivos de comunicaciones), como ocurre con enlaces de fibra óptica y redes locales basadas en conmutadores, las cuales serán estudiadas extensamente en un capítulo posterior. 1.4 Arquitecturas de red Las primeras redes digitales fueron diseñadas para interconectar computadoras de un mismo fabricante. La proliferación de diferentes arquitecturas de cómputo dificultaba enormemente el que computadoras de distintos fabricantes pudiesen comunicarse e interactuar entre sí. Para resolver estas dificultades, se definen estándares que buscan asegurar la interconexión e interoperabilidad entre los dispositivos de distintos fabricantes. Las normas definidas por los estándares atienden distintos niveles de complejidad en la interconexión y conforman lo que se ha dado en llamar una arquitectura de red. En redes de computadoras, la arquitectura màs conocida es el modelo de referencia OSI (Open Systems Interconnection) definido por la Organización Internacional para la Estandarización, el cual se presenta más adelante. Otros órganos de estandarización importantes son: La Unión Internacional de Telecomunicaciones (ITU, International Telecommunications Union). Define recomendaciones para sistemas de telecomunicaciones. ANSI (American National Standards). Define estándares que aplican para los Estados Unidos, muchos de los cuales se ha vuelto estándares internacionales El ETSI (European Telecommunications Standards Institute). Está conformada papor fabricantes de equipo y operadores de redes y aunque es una organización fundada en Europa, tiene ingerencia a nivel global IEEE (Institute of Electrical and Electronics Engineers). El grupo de trabajo 802 del IEEE define la gran mayorìa de los estándares utilizados en redes locales. 1.4.1 Modelo ISO/OSI La Organización Internacional para la Estandarización (ISO, International Standards Organization) definió un modelo de referencia que ayudara a garantizar la interoperación de los distintos sistemas de cómputo interconectados a través de una red de computadoras. Este modelo se conoce como OSI (Open Systems Interconnection). El modelo ISO/OSI sigue una estrategia de \"divide y vencerás\" organizando el problema de comunicación en una estructura jerárquica de capas. Algunos de los principios básicos de diseño son los siguientes[7]: Cada capa debe efectuar una función bien definida La función de cada capa debe seleccionarse con la intención de definir protocolos normalizados internacionalmente Los límites entre las capas deben permitir una descripción pequeña de los servicios ofrecidos por la capa inferior y minimizar las interacciones entre las capas. Una nueva capa debe crearse en situaciones donde se necesita un nivel de abstracción diferente El nùmero de capas debe ser lo suficientmente grande para que funciones diferentes se encuentren en capas diferentes y, por otra parte, debe ser lo suficientemente pequeño para que su integración no sea difícil. La figura 1.17 muestra los principales conceptos del modelo. Cada capa es responsable de resolver una tarea específica de comunicación, ofreciendo sus servicios a la capa inmediata superior a través de puntos de acceso al servicio (SAP, Service Access Point) bien definidos. A través de estos SAP, las capas intercambian unidades de información conocidas como unidades de datos de servicio (SDU, Service Data Unit). Figura 1.17: Principales conceptos en el modelo ISO/OSI. Para resolver su tarea, las capas en un determinado nivel se comunican con capas del mismo nivel en otros dispositivos, a través de los protocolos de comunicaciones intercambiando información contenida en las llamadas unidades de datos protocolarias (PDU, Protocol Data Unit). El modelo ISO/OSI está conformado por las siete capas que se describen a continuación (ver figura 1.18): 1, Capa física Define las características de los elementos necesarios para la conexión así como las de los bits enviados (características eléctricas, ópticas, mecánicas y procedurales). Por ejemplo, define el formato de los conectores, el número de cables utilizados, la velocidad de transmisión y el formato de las señales que representan los bits de comunicación. 2, Capa de enlace de datos Se encarga de dar formato y de proveer una transmisión libre de errores (o al menos, capaz de detectar la ocurrencia de un error) entre dos elementos conectados directamente. Cuando el canal de comunicación es compartido, como en las redes locales, esta capa también es responsable de definir los mecanismos de control de acceso al medio. 3, Capa de red Establece los mecanismos necesarios para encaminar eficientemente la información entre los equipos terminales. Como se observa en la figura 1.18, la responsabilidad de encaminar paquetes de nodo a nodo a través de la red, involucra únicamente a las primeras tres capas del modelo, siendo esta última la responsable de decidir por qué puerto de un nodo de interconexión deberá salir un paquete determinado para acercarlo a su destino. 4, Capa de transporte Es la primera capa que permite tratar las unidades de datos (TPDU, Transport PDU de extremo a extremo (es decir, entre los equipos terminales involucrados en la comunicación). Por ello, esta capa se encarga, sobre todo, de asegurar que la información llegó correctamente a su destino o en su caso, solicitar la retransmisión; de ser necesario, reordenar los datagramas para entregar datos validados a las capas superiores. 5, Capa de sesión Se encarga de controlar el establecimiento y el fin de un diálogo entre dispositivos, permitiendo, por ejemplo, que se restablezca una comunicación desde un punto estable en caso de que falle la infraestructura de comunicaciones. No se han implementado protocolos que provean las funcionalidades de la capa de sesión (ni de la de presentación). 6, Capa de presentación Dado que los equipos terminales tienen arquitecturas heterogéneas (distintos formatos de datos, tamaño de palabra, etcétera), esta capa es responsable (conceptualmente) de transformar los datos intercambiados para para proveer una representación estándar e interoperable entre los equipos terminales. 7, Capa de aplicación Esta capa es la que ofrece los servicios de red (por ejemplo, conexión remota, transferencia de archivos, correo electrónico) a los usuarios de la misma. Figura 1.18: Arquitectura del modelo de referencia ISO/OSI. 1.4.2 Modelo TCP/IP El modelo OSI es un excelente marco de referencia para describir las funciones necesarias para desplegar redes de computadoras. Sin embargo, la implementación de sus protocolos prácticamente no tuvo acogida dada la lentitud de los procesos de estandarización y la complejidad de algunos de los protocolos propuestos. A finales de los años 70, la Agencia de Proyectos de Investigación Avanzada de la Defensa de Estados Unidos (DARPA) se dio a la tarea de desarrollar una red de conmutación de paquetes que conectara las redes de equipos disímiles que empezaban a ser desplegadas en sus centros de investigación. Así nació la Internet de nuestros días. DARPA no podía esperar a que OSI terminara de definir su modelo de referencia. Inspirada en los mismos principios de base, el modelo TCP/IP también define una arquitectura de capas conocida como la pila de protocolos TCP/IP. Para fines prácticos, esta arquitectura puede verse como un modelo de cuatro capas: Aplicación, Transporte, Red y las llamadas capas inferiores (ver figura 1.19). Figura 1.19: Arquitectura del modelo TCP/IP. Capa de aplicación Corresponde a las capas de Aplicación, Representación y Sesión del modelo ISO/OSI y ofrece los servicios de red a los usuarios finales. Aquí se encuentran protocolos como HTTP para navegación y acceso a páginas Web, SMTP para correo electrónico, TELNET, SSH para acceso remoto, FTP para transferencia de archivos, etcétera. Capa de transporte Corresponde en términos generales a la capa de transporte de ISO/OSI. Los dos protocolos principales definidos en esta capa son TCP (de donde el modelo toma parte de su nombre) y UDP. TCP (Transmission Control Protocol) es responsable de garantizar la entrega en orden y sin errores de extremo a extremo. Es un protocolo orientado a conexión. UDP (User Datagram Protocol) es un protocolo sumamente sencillo que se encarga de ofrecer servicios de red sin garantías de entrega, a la capa de aplicación. Más adelante se mostrará con detalle la operación de estos dos protocolos y bajo qué condiciones conviene utilizar cada uno. Capa de red Corresponde a la capa de red de ISO/OSI, responsable de encaminar los paquetes a través de la red. El protocolo encargado de ello es IP (el segundo término en el nombre del modelo), en el que se define el formato de los N-PDU, los identificadores de los equipos terminales y las redes donde se encuentran (las direcciones IP), entre otros elementos. En esta capa también se define una serie de protocolos para intercambiar información sobre la topología de la red (protocolos de enrutamiento) así como protocolos auxiliares para verificar la integridad de la red. Capas inferiores El modelo TCP/IP no define arquitecturas ni protocolos para las capas de enlace de datos ni física. Siendo una arquitectura diseñada para la \"Interconexión de Redes\" (de ahí el nombre Internet), el modelo es agnóstico a las capas inferiores. Suele decirse que IP corre sobre todo (sobre cualquier tipo de red) y todo corre sobre IP (es decir, cualquier aplicación de red) Homogeneizando las comunicaciones con IP en la capa de red, se ocultan las características físicas y tecnológicas de las redes individuales y se logra la conectividad global entre ellas. Esta característica permite, además, incorporar cualquier nueva tecnología de conexión. 1.4.3 Encapsulamiento En las arquitecturas de red presentadas anteriormente, una capa de nivel N utiliza los servicios ofrecidos por la capa inferior (N-1) para realizar sus funciones y a su vez ofrecer sus servicios a la capa superior. La interacción entre capas para ofrecer estos servicios se da a través de los protocolos de comunicaciones. Cada protocolo agrega información adicional (los encabezados del protocolo) para prestar estos servicios. A este proceso se le conoce como encapsulamiento. Para reforzar estos conceptos en la figura 1.20 se muestra cómo interactúan los protocolos de las capas de TCP/IP cuando se consulta una página Web. Figura 1.20: Encapsulamiento en TCP/IP para cargar una página web. Cuando se introduce el identificador de una página web en un navegador (por ejemplo, www.itam.mx), se utiliza un mecanismo de resolución de nombres simbólicos (no mostrado en la figura) para obtener el identificador de red del servidor que alberga la página. Una vez obtenida esta información, se invoca el protocolo de capa de aplicación HTTP para acceder a este servidor. El PDU a este nivel se conoce informalmente como mensaje. De todos los \"servicios\" que ofrece HTTP, el que se utiliza para cargar una página web es el comando GET. HTTP utiliza el servicio de transporte TCP a través del puerto (TSAP) 80. El PDU de TCP (conocido como segmento) agrega información adicional como el número de puerto, números de secuencia y acuses de recibo para verificar la integridad y la entrega ordenada de los datos. TCP utiliza los servicios de IP para encaminar los segmentos hacia el destino, en este caso, el servidor Web. IP agrega información al SDU que recibió de TCP para formar su propio PDU, llamado paquete IP o datagrama. La información más importante que se agrega en los encabezados de IP son las direcciones fuente (el equipo terminal que solicita la página) y destino (la dirección del servidor Web consultado). Hasta aquí terminan las funciones del modelo TCP/IP. La figura 1.20 asume que el equipo terminal está conectado a una red local Ethernet (esa es la \"capa inferior\"), por lo que el paquete IP accede a los servicios de la red local y deposita su información en una trama Ethernet. En el siguiente capítulo se mostrará cómo opera Ethernet y por qué es necesario que a este nivel se definan nuevos identificadores fuente y destino. 1.5 Taxonomía Existen diversas maneras en las que las redes digitales pueden ser clasificadas, por ejemplo, por los servicios que ofrecen (telefonía fija y móvil, televisión, intercambio de información); por su función en la arquitectura de red (redes de acceso, redes de transporte); por la población de usuarios que las utilizan (redes públicas, privadas, corporativas, para el hogar); por su cobertura geográfica. Esta última clasificación es muy común en la literatura, por lo que se presentará brevemente. Redes de área corporal (BAN, Personal Area Network) Se trata de un concepto relativamente reciente en el que los dispositivos utilizan el cuerpo humano como medio de transmisión. Los dispositivos transmiten información entre sí con el simple hecho de tocarlos. Esta tecnología debe utilizar señales de baja potencia para reducir la interferencia entre dispositivos y, sobre todo para evitar efectos nocivos para la salud. Una ventaja del cuerpo como medio de transmisión es que la información no se irradia al ambiente. El Instituto de Investigaciones en Electrónica y Telecomunicación de Corea del Sur ha desarrollado un prototipo que permite intercambiar datos a 5kb/s. Esta clase de dispositivos podría usarse para ofrecer servicios de autenticación, pago electrónico o monitoreo clínico de pacientes. Su área de cobertura es de un par de metros. Redes de área personal (PAN, Body Area Network) Son redes típicamente inalámbricas que interconectan dispositivos de cómputo en un área de cobertura pequeña, alrededor de 10 metros. Las primeras redes PAN utilizaban enlaces infrarrojo para la interconexión, ofrecían velocidades de 2.4kb/s hasta 16Mb/s en un rango de hasta un metro pero los dispositivos debían contar con una trayectoria directa entre ellos, es decir, sin objetos que la obstruyeran. A esto se le conoce en telecomunicaciones como línea de vista (LOS, Line Of Sight). Los estándares actuales, entre los que destacan IEEE 802.15.1, mejor conocido como Bluetooth, IEEE 802.15.4, llamado ZigBee6 y Wireless USB7, no requieren de LOS. Bluetooth 2.0 ofrece velocidades de 3Mb/s mientras que WUSB alcanza los 110Mb/s en distancias de 10 metros. ZigBee, más enfocada a la interconexión de dispositivos, es una red muy simple, de bajo costo, baja velocidad (hasta 250 kb/s) y relativamente segura. Todas ellas están diseñadas para operar en modo ad-hoc, en el que los dispositivos electrónicos se conectan entre sí sin la intervención del usuario. Es decir, los dispositivos identifican a la red, solicitan su ingreso, reciben una dirección y establecen la comunicación por sí mismos. Redes de área local (LAN, Local Area Network) Son las más conocidas en las organizaciones y, de manera creciente, en los hogares. En el capítulo ?? se presentan estas redes. Permiten conectar dispositivos con una cobertura de cientos de metros hasta un par de kilómetros. Históricamente, la tecnología dominante en estas redes ha sido Ethernet, creada por Robert Metcalfe en los laboratorios Xerox PARC a mediados de los años 70 [8] y estandarizada por la IEEE bajo el grupo de trabajo 802.3 8. En sus primeras versiones, los dispositivos se conectan a un medio compartido (un cable coaxial, o un concentrador) en el que se difunde la señal transmitida, que puede ser escuchada por todos. Cuando un dispositivo desea enviar información, verifica que el medio esté libre y la transmite en una trama que tiene, entre otros campos, identificadores del remitente y del receptor. Este último toma la trama del medio; los demás la ignoran. Debido a su gran flexibilidad, facilidad de integración y bajos costos de implementación, se ha observado un crecimiento exponencial de redes locales inalámbricas basadas en la familia de estándares IEEE 802.119 tanto en las organizaciones privadas como en el hogar y en áreas públicas como aeropuertos, parques y cafeterías, sobre todo para dar acceso a la red Internet en los llamados hot-spots. Estas redes, también conocidas como WiFi, ofrecen velocidades nominales que alcanzan los 500 Mb/s. Redes de área de campus (CAN, Campus Area Network) Conforme fueron diseminándose las redes locales surgió la necesidad de conectarlas entre sí de manera eficiente en áreas que podían abarcar unos cuantos kilómetros, como hospitales, aeropuertos, campus universitarios, y edificios corporativos. Esta interconexión podía realizarse por medio de conmutadores ATM, o por medio de tecnologías específicas para ello, como FDDI (Fiber Distributed Data Interface). En la actualidad, la interconexión suele darse a través de enlaces punto a punto (típicamente enlaces ópticos) entre conmutadores Ethernet o enrutadores IP. Redes de área metropolitana (MAN, Metrtopolitan Area Network) Con una cobertura de decenas de kilómetros, en esta categoría suelen concentrarse dos grupos de tecnologías: aquellas utilizadas principalmente para interconectar redes locales dentro de una ciudad y aquellas utilizadas como redes de acceso, principalmente a Internet. Para la interconexión de redes locales, la tecnología dominante es MetroEthernet (IEEE 802.3ah) la cual evolucionó de las redes LAN, con las que los usuarios tienen una larga familiaridad. MetroEthernet puede ser implementada sobre líneas de cobre aunque con mayor frecuencia su infraestructura se basa en fibras ópticas. Si el proveedor utiliza DWDM, puede alcanzar velocidades de hasta 100Gb/s. Redes de área amplia (WAN, Wide Area Network) En esta categoría, en la que también se incluyen las redes de área regional (RAN, Regional Area Network), se cubren grandes extensiones, incluso varios países. La mayoría de estas redes está integrada a la infraestructura de transporte (alambrada) de los grandes operadores. Típicamente están formadas por nodos de conmutación de gran velocidad interconectados entre sí con enlaces de fibra óptica utilizando tecnologías como ATM, SONET/SDH y WDM. La norma IEEE 802.22, tiene como objeto proveer acceso inalámbrico fijo a regiones de hasta 100 km de radio en áreas con baja densidad poblacional. Utiliza frecuencias sin licencia en la banda originalmente establecida para la radiodifusión de televisión. El estándar hace uso de radios cognitivos. Posee la gran ventaja de no interferir con dispositivos usando frecuencias con licencia. Esta tecnología resulta de particular interés en países en desarrollo y en áreas rurales. Redes de área global (GAN, Global Area Network) Las redes de área global cubren un área geográfica ilimitada interconectando una gran cantidad de redes. Este es el caso de las redes telefónicas fijas a escala mundial, e integradas casi totalmente con sus contrapartes celulares. Otro ejemplo evidente es Internet, la gran \"red de redes\", que ha rebasado las fronteras de la tierra con la propuesta de iniciativas para lanzar sondas espaciales que utilizan enrutadores con el protocolo IP para enviar información a la tierra. 1.6 Problemas Problema 1.1 Alguien sugiere que \"...el espectro radioeléctrico es como una autopista y las bandas de frecuencia son como sus carriles\". Admitiendo que el ejemplo es válido en el contexto en que se presentó, ¿Qué sería la frecuencia? ¿La longitud de onda? La autopista tiene tres carriles en una dirección y tres en la dirección contraria. ¿Podría equipararse a una comunicación Full duplex, Half duplex, Simplex o ninguna de éstas? ¿Qué técnica de multiplexaje sería mejor representada con un automóvil que se cambia de un carril a otro continuamente? (TDM, FDM, CDM, Ninguna) ¿Con qué se podría relacionar el que un automóvil transporte 1, 2 o más pasajeros? Problema 1.2 Las muestras de una señal determinada, tienen los valores 7.1 V, 4.0 V, 0.3 V y 2.6V. ¿Cómo se representarían estas muestras en un sistema PCM con codificación de 5 bits? Problema 1.3 Unos sensores ambientales generan señales con frecuencia máxima de 12 kHz. Se toman muestras de estas señales y se transmiten a través de un canal de 100 kHz. Considerando el teorema de Nyquist, ¿Cuántas señales pueden ser multiplexadas en ese canal? Opciones: 1; 2; 4; 8; 10; 16 Problema 1.4 ¿Cuáles son las propiedades de una señal portadora que se pueden modificar para que transporte información? Longitud de onda Frecuencia Fase Polaridad Amplitud Dirección Voltaje Campo electro-magnético Problema 1.5 Encuentre la longitud de onda de las siguientes señales: (a) 8 kHz; (b)1500 kHz; (c) 1.3 GHz Problema 1.6 ¿Qué diferencia fundamental hay entre un circuito y un circuito virtual? Problema 1.7 Describe dos razones para modular la información que se desea transmitir Problema 1.8 Para las siguientes afirmaciones, indique si son correctas o no. Justifique muy brevemente su respuesta En una red, todos los equipos terminales (hosts) implementan la capa de transporte En una red, todos los enrutadores implementan la capa de transporte En una red, todos los enrutadores implementan la capa de red Un enrutador puede dar servicio a varios protocolos de capa de transporte Una de las funciones de la capa de red es encaminar de forma segura y confiable los paquetes de la fuente a su destino Problema 1.9 ¿Qué significan las siglas OSI? ¿Qué capa del modelo es la responsable de garantizar la integridad de las comunicaciones de extremo a extremo? ¿Cuál es la función de la capa física? Problema 1.10 En una comunidad, todas las computadoras pueden comunicarse entre sí con enlaces de micro ondas hacia una estación base con una gran antena en el centro geográfico de la comunidad. Suponiendo que no existen problemas de congestión, ¿En qué capa conviene más administrar estas comunicaciones: enlace, red o transporte? Justifique brevemente. Suponga ahora que en la comunidad se depliega una serie de pequeñas radio bases con cobertura reducida. ¿En qué capa conviene más administrar estas comunicaciones: enlace, red o transporte? Justifique brevemente. Problema 1.11 Resuelva el siguiente sudoku. Capa del modelo de OSI encargada de establecer la ruta por la que viajarán los paquetes Capa del modelo de OSI responsable de verificar la integridad de la información de extremo a extremo (c)Capa del modelo de OSI que establece las características físicas, mecánicas, eléctricas, de los enlaces Si bien la suma puede ser infinita, en general basta con un número relativamente pequeño de componentes senoidales para representar con una precisión aceptable la señal Recordemos que una señal compleja puede representarse por una suma de señales senoidales La reservación de recursos ocurre en las redes de telefonía fija. Las redes móviles son mucho más complejas y no se puede garantizar que los recursos necesarios estén disponibles al pasar de una célula a otra En distintas arquitecturas de red, estos bloques reciben diferentes nombres, como tramas, celdas, segmentos y datagramas En muchas arquitecturas de red, a este identificador se le llama identificador de circuito virtual (VCI, Virtual Circuit Identificator) IEEE 802.15 WPAN Task Group 1. http://www.ieee802.org/15/pub/TG1.html Certified Wireless USB. http://www.usb.org/developers/wusb/ http:// www.ieee802.org /3/ http://www.ieee802.org/11/ "],["redes-locales.html", "Capítulo 2 Redes locales Resumen 2.1 Introducción 2.2 Ethernet/IEEE 802.3 2.3 Redes locales inalámbricas 2.4 Conmutacion 2.5 Protocolo Spanning Tree 2.6 Rapid STP 2.7 Agregación de enlaces 2.8 Redes locales virtuales 2.9 Problemas", " Capítulo 2 Redes locales Resumen Una red local está formada por un conjunto de computadoras y otros dispositivos interconectados dentro de un área geográfica limitada con el fin de compartir recursos internos (como discos e impresoras) e intercambiar información. En las redes en las que la interconexión se hace a través de cables eléctricos (y ópticos), la tecnología dominante ha sido Ethernet/IEEE 802.3. Por su parte, las redes locales en las que la intercomunicación se hace a través de señales electromagnéticas, la tecnología que impera es WiFi/IEEE 802.11. En este capítulo se presentan brevemente las principales características de Ethernet, su protocolo de acceso al medio CSMA/CD y una síntesis de la evolución de esta tecnología. Así mismo, se describen brevemente los principios de operación de IEEE 802.11, el protocolo CSMA/CA y su evolución. El capítulo también aborda el Spanning Tree Protocol (STP) y el Rapid Spanning Tree Protocol (RSTP). Estos protocolos se utilizan para evitar bucles en las topologías de red y garantizar una comunicación eficiente. Se explican los conceptos básicos de cómo funcionan estos protocolos y su importancia en la configuración de redes locales. Por último, se introduce el concepto de VLANs (Virtual LANs), que permiten dividir una red física en múltiples redes lógicas. Se explica cómo las VLANs pueden ayudar a mejorar la seguridad y la eficiencia de una red, al permitir la segmentación y el control de acceso a diferentes grupos de dispositivos. 2.1 Introducción Con el progreso tecnológico, aparecen en los años 70 equipos de cómputo mucho más poderosos que los desarrollados en la década anterior y mucho más económicos. Es la transición del mainframe a la minicomputadora. Esta transición permite que muchas más organizaciones puedan adquirir su propia computadora; de hecho, organizaciones grandes y medianas podían adquirir varias computadoras para sus distintas unidades de negocio. Surge entonces la necesidad de interconectar las computadoras dentro de la organización entre sí, y con los equipos periféricos como terminales, impresoras y dispositivos de almacenamiento externo, los cuales también se empiezan a desplegar masivamente en las organizaciones. Así nacen las redes locales (LAN, Local Area Network), encargadas de interconectar los dispositivos de cómputo en un área geográfica acotada a unos cuantos cientos de metros. Prácticamente todos los fabricantes de equipo de cómputo tenían soluciones propietarias para desplegar LANs. El grupo de trabajo 802 del IEEE (Institute of Electrical and Electronic Engineers) en Estados Unidos, retuvo y estandarizó las tecnologías que más potencial tenían para ser implementadas, como Token Bus (IEEE 802.4) popular en medios industriales, Token Ring (IEEE 802.5), derivada principalmente de tecnologías desarrolladas por IBM y muy utilizada en el sector financiero de la época, y Ethernet (IEEE 802.3) la cual terminó siendo, por mucho, la tecnología dominante en LANs cableadas. Un requisito muy importante para el despliegue de las LAN en aquella época, era que fueran relativamente fáciles de implementar y de bajo costo. Como se ha mencionado en capítulos anteriores, los costos pueden reducirse sustancialmente si se comparten recursos. En las redes locales se comparte el canal de comunicación (el medio) y deben definirse claramente las reglas bajo las cuales este canal se comparte. Estas reglas son los Protocolos de control de acceso al medio (MAC, Media Access Control). Los equipos de cómputo acceden al medio compartido a través de la tarjeta de red (NIC, Network Interface Card). Cada tarjeta tiene un identificador conocido como la dirección MAC. En general se asume que un dispositivo tiene solo una tarjeta de red (al menos solo una tarjeta de red activa), por lo que suele decirse (incorrectamente) que la dirección MAC es un identificador del dispositivo conectado a la red. En IEEE 802, las direcciónes MAC están formadas por seis bytes10 (48 bits) con el formato que se muestra en la figura 2.1. Si el penúltimo bit del primer byte es cero, la dirección MAC es única universalmente. En este caso, como se muestra en la figura, los primeros 3 bytes son un identificador único asignado al fabricante de la tarjeta de red y los últimos 3 bytes son un número de serie de tarjeta. Se el bit vale uno, entonces la dirección es única dentro de la red local. La dirección MAC es administrada localmente, lo cual prácticamente nunca ocurre. Figura 2.1: Formato de una dirección IEEE de 48 bits. Si el bit menos significativo del primer byte es cero, se trata de una dirección unicast, es decir una dirección de una tarjeta de red. Si su valor es uno, la dirección es de grupo (multicast) y la trama está dirigida a varios dispositivos (a varias tarjetas NIC) conectados a la red local. Si todos los bits son 1, se trata de una dirección de difusión (broadcast) y la trama está dirigida a todos los dispositivos en la red local. 2.2 Ethernet/IEEE 802.3 Ethernet fue desarrollada a principios de los años 70 por Robert Metcalfe en los laboratorios de Xerox en California y, con muy pequeñas modificaciones, es la base del estándar IEEE 802.3. Ethernet toma su nombre como recuerdo de aquella teoría del siglo XIX según la cual el universo estaba suspendido en una especie de éter por el que las ondas electromagnéticas podían propagarse. En las primeras versiones de Ethernet el canal compartido era un cable coaxial al que se conectaban los dispositivos. Cuando una computadora desea mandar información a otro dispositivo, simplemente forma un mensaje (una trama) con la información a enviar, las direcciones (MAC) del emisor (la fuente) y el receptor (el destino) y algunos campos adicionales que se describen más adelante. Una vez formada la trama, ésta se envía en serie (es decir, bit a bit) por el cable como una secuencia de señales eléctricas. Estas señales se propagan por el cable por lo que todos los dispositivos conectados a él pueden percibir que hay actividad en el medio. Los dispositivos toman la trama, revisan la dirección destino y si ésta no es su propia dirección o una dirección de difusión, simplemente descartan la trama; de lo contrario, se valida la integridad de la trama y si ésta no contiene errores, la información se entrega al proceso correspondiente, típicamente, el encargado de procesar el paquete en la capa superior (capa 3 de OSI). Al tener un canal compartido, en estas redes pueden existir colisiones, es decir, transmisiones simultáneas de dos o más dispositivos que interfieren entre sí. Para regular la forma de acceder al medio, Metcalfe concibió el protocolo CSMA/CD (Carrier Sense Multiple Access with Collision Detection), que establece cuándo se puede intentar transmitir, cómo detectar una colisión y, si ésta ocurre, qué hacer para enviar nuevamente una trama. 2.2.1 CSMA/CD Existen varios dispositivos conectados a la red que desean comunicarse (MA, Multiple Access); cuando una estación desea transmitir una trama, escucha primero si detecta una señal en el medio (CS, Carrier Sense). Si el canal está libre, envía la trama; de lo contrario, espera a que se desocupe y transmite inmediatamente la trama. Sin embargo, con el comportamiento anterior, es fácil imaginar el siguiente escenario: La computadora \\(A\\) desea enviar una trama, sensa el medio, lo encuentra libre e inicia la transmisión. Poco después, \\(B\\) desea enviar una trama pero encuentra el medio ocupado y espera a que se libere. Más adelante, \\(C\\) desea enviar una trama; como \\(A\\) no ha terminado con su transmisión, \\(C\\) también se pone en espera de que se libere el medio. Cuando \\(A\\) termina de transmitir, \\(B\\) y \\(C\\) detectan que el medio está libre e inician la transmisión de sus propias tramas. Por supuesto, las señales de estas tramas van a interferir entre sí. Como la potencia de las dos señales es relativamente igual, no se podrá recuperar la información de ninguna de las dos tramas. Ha ocurrido una colisión. En CSMA/CD el dispositivo que transmite debe escuchar el medio durante la emisión de la trama y verificar que lo que escucha es igual a lo que está enviando. De no ser así, la trama ha sido dañada por una colisión (CD, Colission Detection). En ese momento, el emisor aborta la transmisión de la trama y en su lugar envía una pequeña señal para reforzar la colisión (jamming signal) y garantizar que los demás dispositivos involucrados en la interferencia también puedan detectarla. Después de enviar esta señal el emisor espera un tiempo aleatorio y vuelve a intentar transmitir la trama empezando por sensar si el medio está libre. El tiempo que debe esperar un dispositivo antes de intentar retransmitir su trama se calcula mediante el algoritmo conocido como espera exponencial binaria truncada): \\[\\begin{aligned} &amp;k = min(\\text{Número de intentos}, 10)\\\\ &amp;r = \\text{Valor aleatorio}\\,\\,[0, 2^k)\\\\ &amp;\\text{Tiempo de espera}\\,\\,= r * 2\\tau \\end{aligned}\\] Los intervalos de espera son múltiplos de \\(\\tau\\), conocido como la ventana de colisión o ranura de tiempo de colisión la cual se describe más adelante. El intervalo de espera aumenta exponencialmente en potencias de 2 a cada intento fallido de transmisión. Entre más grande es este intervalo, menor es la probabilidad de que los dispositivos que han colisionado, elijan el mismo tiempo de espera y colisionen nuevamente. Considere el caso de una red con poca carga en el que las tramas de dos dispositivos colisionan por primera vez. Cada una calcula el intervalo de espera que puede ser cero o un \\(\\tau\\). Con solo dos valores, la probabilidad de que el tiempo de espera sea el mismo, es de 50%. Si en el segundo intento colisionan nuevamente, el rango se amplía de 0 a 3, por lo que se reduce a 25% la probabilidad de calcular el mismo tiempo de espera, y así sucesivamente. El intervalo máximo de espera es \\(2^{10}=1024\\,\\tau\\). Después de 16 intentos fallidos, se asume que la red está demasiado cargada o que hay un defecto en la capa física, por lo que se aborta el intento de transmisión y se señala un error hacia las capas superiores. Con este protocolo MAC, Ethernet permite la entrega inmediata de tramas cuando hay poco tráfico en la red; la probabilidad de colisión y por consiguiente el tiempo de espera aumenta conforme se va incrementando el tráfico. En redes con alta carga, el tiempo de espera puede ser muy largo, pero sobre todo, no predecible (no determinista). La ventana de colisión La ventana de colisión se define como el tiempo máximo que puede transcurrir antes de detectar una colisión. Su valor depende de varios factores, como la velocidad de transmisión, la longitud de la red y la velocidad de propagación de las señales en el medio de transmisión. Para entender más claramente este concepto, considere la figura 2.2. Figura 2.2: Formato de una dirección IEEE de 48 bits. El peor caso ocurre cuando hay conflicto entre las dos estaciones más extremas conectadas a la red. Son las estaciones \\(A\\) y \\(B\\) en la figura 2.2}. En \\(t_0\\) \\(A\\) inicia su transmisión y la señal se propaga por el cable. El tiempo que le toma a la señal propagarse por todo el cable es \\(t_p\\), el tiempo o retardo de propagación. Justo antes de llegar al extremo opuesto, en \\(t_p-\\delta\\), \\(B\\) desea transmitir, sensa el medio, lo encuentra libre e inicia su transmisión. \\(B\\) detecta inmediatamente la colisión, en \\(t_p\\), pero ésta debe propagarse de regreso hasta \\(A\\), lo que ocurrirá en \\(2t_p\\). Así, la ventana de colisión queda definida como \\(2t_p\\), dos veces el retardo de propagación de la señal, de un extremo a otro de la red. Esta ventana de colisión fue fijada en \\(51.2\\mu \\text{seg}\\) y determina muchos de los aspectos fundamentales de las redes Ethernet/IEEE 802.3, como son: El diámetro máximo de la red. Claramente, \\(2t_p \\leq 51.2\\mu \\text{seg}\\). En la primera especificación de IEEE 802.3, esto corresponde al retardo de ida y vuelta de una red formada por cinco segmentos de 500 m c/u interconectados por cuatro repetidores11, por lo que el diámetro máximo de la red local es de 2,500 m. El tamaño mínimo de la trama. Dado que la estación emisora (\\(A\\) en la figura 2.2) debe ser capaz de detectar que ha ocurrido una colisión, ésta debe estar inyectando bits durante al menos \\(51.2\\mu \\text{seg}\\). En este tiempo se pueden emitir 512 bits (64 bytes) si éstos son transmitidos a 10 Mbps, la velocidad definida en la primea especificación de IEEE 802.3. El tiempo máximo en que puede detectarse una colisión. Efectivamente, este intervalo es la definición de la ventana de colisión y muestra, en el peor escenario, la cantidad de información que una estación estaría emitiendo inútilmente pues parte de la trama ha sido afectada por la colisión. La unidad de tiempo utilizada en el algoritmo de retransmisión. Como se recordará, el algoritmo de espera exponencial truncado utiliza un parámetro \\(\\tau\\) cuyo valor es, justamente, \\(51.2 \\mu \\text{seg}\\). 2.2.2 Formato de la trama El formato de la trama Ethernet/IEEE 802.3 se muestra en la figura 2.4. Los campos que la conforman se describen más adelante. Estrictamente hablando, el preámbulo y el delimitador de inicio de trama no forman parte de la trama en IEEE 802.312 sino que se utilizan para sincronización, pero es muy frecuente incluirlos al presentar el formato de las tramas. Como la red debía ser de bajo costo, las tarjetas de red no podían tener relojes de muy alta precisión. Para asegurar que los dispositivos se mantendrían sincronizados durante la transmisión de una trama, las primeras versiones de Ethernet utilizan una técnica de señalización llamada codificación Manchester. La señal tiene dos niveles (bajo y alto) y los bits a transmitir se codifican como una transición entre estos niveles al centro de la duración del bit: Un 1 se codifica como una transición del nivel bajo al alto, y un 0 como una transición del nivel alto al bajo (ver figura 2.3). Figura 2.3: Codificación Manchester utilizada en Ethernet a 10 Mbps, Como se recordará, las tramas deben tener una longitud mínima de 64 bytes para garantizar que se pueden detectar colisiones en redes con el diámetro máximo de 2500 metros. También se especifica un tamaño máximo de 1518 bytes (1500 de información) para evitar que un dispositivo se apropie del medio de transmisión por un período de tiempo muy largo. Efectivamente, al limitar el tamaño máximo de trama, se asegura que el emisor liberará el canal tras un periodo corto bien definido. Además, entre la emisión de una trama y otra, un dispositivo debe dejar un intervalo de por lo menos 12 bytes. A este intervalo se el conoce como IFG, Interframe gap y permite que otros dispositivos esperando acceder al medio, puedan hacerlo. Figura 2.4: Formato de una trama Ethernet/IEEE 802.3. Preámbulo. La codificación Manchester garantiza que siempre habrá una transición a la mitad de un intervalo de bit y con ayuda de estas transiciones se mantiene la sincronización en los dispositivos. Sin embargo, al inicio de la transmisión de la trama el proceso de sincronización es más complejo pues se debe asegurar una referencia inicial. Esa es la función del preámbulo que manda 7 bytes (56 bits) con el patrón 10101010. Al detectar una señal en el medio, los dispositivos van ajustando sus relojes hasta reconocer el patrón alternante de 1 y 0. Delimitador de inicio de trama. (SFD, Start Frame Delimiter) es un byte formado por el patrón 10101011. El último par de bits interrumpe la secuencia alternante de 1 y 0 formada por el preámbulo e indica que a partir de los siguientes bits se encuentran los campos de la trama. Dirección destino. Contiene el identificador del dispositivo a quien va dirigida la trama. Como se recordará de la figura 2.1, si el bit menos significativo del primer byte es 1, la trama está dirigida a varios (inclusive a todos) equipos en la red. IEEE 802.3 permite direcciones de 2 bytes, aunque su uso es prácticamente nulo. Dirección fuente. Contiene el identificador del emisor de la trama. Por supuesto, no tiene sentido que este campo tenga una dirección de difusión, debe ser una dirección unicast. Longitud o tipo de trama. Para Ethernet, este campo contiene el tipo de trama, es decir, es un identificador para poder reconocer qué tipo de datos están siendo transportados por la trama. Por ejemplo si este campo contiene el valor 08 00, el campo de información contiene un paquete IP, mientras que si es 08 05, se trata de un paquete X25. En IEEE 802.3 este campo indica la longitud del campo de información de la trama. Bajo el estándar IEEE 802.3, el tipo de información siempre es una trama IEEE 802.2. Así, este campo permite distinguir entre tramas Ethernet e IEEE 802.3: Si el valor es menor a 1500, se está especificando una longitud y por lo tanto se trata de una trama IEEE 802.3. Información. En este campo, también llamado carga útil (payload), viajan los datos transportados por la trama de un dispositivo a otro. Como el tamaño máximo de trama es de 1518 bytes y se ocupan 18 para los demás campos (dirección destino, dirección fuente, tipo o longitud y FCS), la cantidad máxima de datos que pueden ser transportados en una trama, es de 1500 bytes. Como el tamaño mínimo de la trama es de 64 bytes, el tamaño mínimo del campo de información debe ser de 46 bytes. Si se desean mandar menos datos, se deben agregar bytes de relleno (padding) para completar el tamaño mínimo. Secuencia de verificación. (FCS, Frame Check Sequence) Es un campo formado con un código cíclico redundante (CRC) para verificar la integridad de la trama. El emisor calcula el CRC y lo agrega a este campo. A la recepción de la trama el destinatario hace lo mismo y compara el CRC calculado contra el recibido. Si son diferentes, se puede asegurar que la trama ha sido alterada y debe descartarse. Si son iguales, se tiene una muy alta probabilidad de que la trama ha llegado sin error. 2.2.3 Implementaciones Como se mencionó en la sección anterior, la especificación original de Ethernet define una velocidad de transmisión de 10 Mbps y utiliza como medio segmentos de cable coaxial con impedancia de 50 ohms. Este cable tiene un grosor aproximado de un centímetro y una longitud máxima de 500 metros. El alcance y las capacidades de la red pueden aumentarse conectado dos segmentos a través de repetidores. Puede haber varios segmentos de 500 metros, pero entre dos computadoras cualesquiera en la red, la distancia máxima permitida es de 5 segmentos (2,500 metros) de los cuales, solo tres pueden tener dispositivos de cómputo. La red de la figura 2.5 muestra un ejemplo de un despliegue válido. Figura 2.5: Un despliegue de red 10Base5. Se han venido desarrollando variantes a la norma original para responder a nuevos requerimientos; así ha surgido una gama de tecnologías que han sido incorporadas en actualizaciones de la norma IEEE 802.3. Para poder identificar rápidamente una implementación particular, se estableció una notación especial formada por tres parámetros: La velocidad de transmisión, la técnica de señalización y el tamaño del segmento o el tipo de medio. Por ejemplo, la especificación original descrita en los párrafos anteriores, es conocida como 10Base5: Opera a 10 Mbps, con señalización en banda base13 y el tamaño de segmento es de 500 metros (5 * 100). La tabla 2. resume algunos ejemplos de variantes que se han hecho a la norma. Algunos ejemplos de implementaciones de redes locales Norma Medio Señalización Velocidad Tam. segmento (Mbps) (metros) 10Base5 Cable coaxial grueso Manchester 10 500 10Base2 Cable coaxial delgado Manchester 10 185 10Borad36 Cable coaxial 75 ohm DPSK Modulado 10 1800 10BaseT Par trenzado UTP Manchester 10 100 100BaseTX Par trenzado UTP 4B5B-MLT3 100 100 1000BaseSX Fibra óptica multimodal 8B10B-NRZ 100 550 10Base5 El grosor de un centímetro del cable, hace que éste sea muy inflexible. Típicamente el cable corre por el piso o el plafón falso. Un dispositivo que se quiere conectar a la red necesita de un adaptador formado por un cable de 15 pares de hilos y un dispositivo llamado unidad de acoplamiento al medio (MAU, Medium Attachment Unit) que perfora el recubrimiento del cable coaxial para entrar en contacto con el núcleo (ver figura 2.6. La longitud máxima del cable de interfaz es de 50 metros. Figura 2.6: Unidad de acoplamiento conectada a cable coaxial grueso (10Base5). 10Base2 Esta implementación, también conocida como cheapernet o de cable delgado, utiliza un cable coaxial de 5mm de diámetro. Fue concebida como una alternativa más económica a 10Base 5. Como el cable delgado es más propenso al ruido, la longitud máxima de los segmentos se redujo a 185 metros. Por otro lado, el cable es más flexible, por lo que éste puede llegar al dispositivo que se quiere conectar sin necesidad de la interfaz MAU. Por lo general, en estas redes se utilizaba un acoplamiento al cable con un con un conector BNC tipo T como se muestra en la figura 2.7. La velocidad de transmisión, la técnica de señalización, el número de segmentos y repetidores se mantienen igual que en 10Base5. De hecho, se pueden combinar en una misma red segmentos con las dos tecnologías. Figura 2.7: Conector T para redes 10Base2. 10Broad36 Desarrollado a mediados de los años 80, esta norma se concibió para transmisión de datos en la infraestructura de las redes de televisión por cable que utilizan un cable coaxial con impedancia de 75 ohms. Su velocidad también era de 10 Mbps pero utilizaba una codificación DPSK en una portadora para desplazar la señal a otra banda de frecuencia. Así, se podrían tener en el mismo cable señales de televisión y transferencia de datos simultáneamente. Las señales viajaban en una sola dirección hacia un dispositivo en el extremo del cable (head end) a una distancia hasta de 1800 metros, que enviaba la señal de regreso en otra frecuencia o en otro cable. En total, la trama viajaría hasta 3600 metros (de ahí el 36 de la notación). Por la complejidad y el costo de los componentes, esta tecnología tuvo muy poca aceptación. 10BaseT Esta implementación utiliza como medio de transporte, pares de cobre trenzados no blindados (UTP, unshielded Twisted Pair) muy similares a los que se ocupan en la red telefónica. De esta manera, se puede aprovechar el tendido de cable trenzado en ductos y regletas que se realiza durante la construcción del edificio, llamado cableado estructurado. La T en la notación corresponde al twisted pair. Este cable llega a paneles de distribución donde se habilitan servicios de voz (conexiones al conmutador telefónico) o servicios de datos (conexiones a la red local). Para este último caso, la tarjeta del dispositivo tiene un conector RJ-45 (ver figura 2.8) al que se conecta un cable de par trenzado. El otro extremo del cable se conecta a una roseta que forma parte del cableado estructurado. Figura 2.8: Cable UTP con conector RJ-45 para red 10BaseT. En el panel de distribución, se hace una segunda conexión hacia un dispositivo (un concentrador) que habilita los servicios de red (figura 2.9). Se trata de un repetidor con múltiples puertos: Cuando recibe una señal por uno de sus puertos, la regenera y reenvía por todos los demás. Si recibe señales simultáneamente por varios puertos, el repetidor asume que se ha generado una colisión y envía una señal especial para que todas las estaciones conectadas a él la detecten y se active el mecanismo de espera y reintento. Figura 2.9: Concentrador 10BaseT en panel de distribución. Dado que el par trenzado no blindado es mucho más vulnerable a las interferencias electromagnéticas que el cable coaxial, en 10BaseT la distancia máxima entre una estación y el concentrador es de solo 100 metros. Sin embargo, la limpieza del cableado estructurado, la comodidad de poder habilitar o reconfigurar servicios en el panel de distribución, la posibilidad de aprovechar el cable telefónico en vez de tener que hacer nuevos tendidos, y la facilidad de administrar centralmente desde el concentrador los flujos de las estaciones, hicieron que esta tecnología fuera muy bien aceptada por los usuarios. 10BaseTX A mediados de los años 90 se hizo evidente la necesidad de contar con redes locales de mayor velocidad y surgió una variante de IEEE 802.3 a 100 Mbps, también llamada FastEthernet. Su implementación más popular es 100BaseTX: La red a 100 Mbps en banda base que utiliza dos pares trenzados no blindados de categoría 5 o superior14. Un par se utiliza para transmitir y el otro para recibir. La configuración de estas redes es igual a la de 10BaseT: Los dispositivos se conectan a través del cableado estructurado a un concentrador (en la actualidad, se conectan a un conmutador) en el panel de distribución. Para ofrecer velocidades de 100 Mbps en UTP, esta tecnología utiliza una codificación 4B5B-MLT3. Sin entrar en muchos detalles, esta técnica reconoce tres niveles de voltaje (positivo, cero o negativo) por lo que se puede mantener una velocidad alta con un baudaje notablemente más bajo: 30 MHz en este caso. 10BaseSX La demanda por más capacidad en las redes locales se empezó a acelerar en el presente milenio. Rápidamente surgieron implementaciones para ofrecer servicios a 1 Gbps, 10 Gbps y se han establecido normas a 40 y 100 Gbps. Muchos despliegues de estas tecnologías utilizan enlaces de fibra óptica. En particular, 1000Base-SX es una red a 1 Gbps con señalización en banda base, que transmite su información en una fibra óptica multimodal, por lo que su cobertura es corta (SX significa short range), de solo 550 metros mientras que despliegues con fibra monomodal pueden alcanzar varios kilómetros. En prácticamente todas estas redes las estaciones están conectadas a puertos dedicados en un conmutador donde las colisiones ya no se generan. Sin embargo, se mantienen los parámetros de la red como los tamaños máximo y mínimo de trama. 2.3 Redes locales inalámbricas Las redes locales inalámbricas (WLAN, Wireless Local Area Network) permiten resolver varias de las restricciones derivadas de utilizar un punto de contacto en las redes locales convencionales. La evolución de equipos de cómputo portátiles asociados a una red local, permite por ejemplo, que un empleado pueda desplazarse por la empresa sin perder el contacto con la red local (y por tanto, con la información que necesita). Entre las principales razones que han motivado el uso de WLANs podemos mencionar la gran flexibilidad que estas redes ofrecen: es posible reubicar los equipos de cómputo sin tener que modificar el cableado de la red; asimismo, crear una nueva red o bien agregar nodos a una red ya existente, puede hacerse de inmediato sin tener que modificar la infraestructura de comunicación. En los úlitmos años se observa un crecimiento exponencial en el despliegue de estas redes, sobre todo de aquellas basadas en la norma IEEE 802.11, también conocida como WiFi. Aunque se han desarrollado redes inalámbricas con señales infrarrojas, prácticamente todas las redes actuales utilizan para su comunicación señales electromagnéticas en algunas de las bandas del espectro que no requieren autorización para su uso. Son las llamadas bandas para aplicaciones industriales, científicas y médicas (ICM); en WiFi se utilizan las frecuencias en el bloque ICM de 2.4 GHz y de 5 GHz. Algunas de estas frecuencias están siendo extensamente utilizadas por otros dispositivos como teléfonos inalámbricos, controles remotos, dispositivos de manos libres, sensores inalámbricos, etc., por lo que las redes inalámbricas que operan en estas bandas deben ser diseñadas para trabajar bajo interferencias considerables. Por ello, estas redes utilizan la técnica de espectro disperso presentada en la sección 1.3.3. Todos los elementos de las redes locales inalámbricas basadas en espectro disperso utilizan el mismo código de dispersión junto con alguno de los mecanismos de control de acceso que se mencionan en la sección siguiente. El hecho de utilizar un código de dispersión único, permite que esa red coexista con otras redes o con otros sistemas en la misma banda de frecuencias [9], [10]. La mayor parte de las WLAN puede configurarse en la actualidad de una de dos maneras: Redes AdHoc y redes basadas en infraestructura [11], [12]. En las primeras, también llamadas redes entre pares, varios dispositivos conforman una red para intercambiar información sin contar con el apoyo de elementos auxiliares (ver figura 2.10). Este tipo de red es muy conveniente para conformar grupos de trabajo temporales en reuniones, conferencias, etc. En la norma IEEE, una configuración AdHoc es llamada IBSS (Independent Basic Service Set). Figura 2.10: Red inalámbrica AdHoc o IBSS. En la segunda configuración (mucho más popular en la actualidad), las WLAN se utilizan como una extensión a la infraestructura de red basada en cable con que ya cuenta la organización donde se instala la red. En esta configuración, es frecuente que los nodos inalámbricos, llamados estaciones remotas, solicitan servicios e información a través de puntos de acceso (AP, Access point) llamados estaciones base. Un AP dando servicio a varias estaciones remotas se conoce como BSS (Basic Service Set); varios APs conectados entre sí de forma cableada o inalámbrica, conforman un ESS (Extended SS), como el que se muestra en la figura 2.11. Figura 2.11: Red inalámbrica basada en infraestructura 2.3.1 Protocolo de Acceso Diseñar un protocolo de acceso para WLANs resulta mucho más complejo que hacerlo para redes locales basadas en cable por varias razones: se deben considerar distintas configuraciones como las redes AdHoc y aquellas basadas en infraestructura; perturbaciones ambientales como interferencias y variaciones en la potencia de la señal, introducen variaciones severas en el tiempo de acceso y en la tasa de errores de transmisión; al contar con equipos móviles se pueden presentar conexiones y desconexiones repentinas en la red; debe contarse con un mecanismo de relevo entre celdas para atender a nodos móviles que pasan del área de cobertura de una celda a otra (roaming), etcétera. En IEEE 802.11 se optó por un protocolo de control de acceso que es una variación de CSMA/CD utilizado en Ethernet/IEEE 802.3. Se trata de CSMA/CA (Carrier Sense Multiple Access with Colision Avoidance). Al igual que en CSMA/CD, cuando una estación desea transmitir, primero verifica que el medio de comunicación esté libre (es decir, sensa la portadora). Si éste está libre, transmite su información y si no, espera a que se libere el medio y transmite. Sin embargo, en las redes inalámbricas, esto no garantiza que no haya colisiones y éstas no pueden detectarse debido, entre otros factores, al problema conocido como de la terminal oculta: un dispositivo inalámbrico puede transmitir con la potencia suficiente para que sea escuchado por el AP, pero no por otra estación que también desea transmitir y que por tanto no detecta la transmisión. En la figura 2.12, la estación B desea transmitir, sensa el medio y no es capaz de detectar la energía de la trama que en ese momento está generando la estación A. La colisión se produce cerca del AP. Figura 2.12: El problema de la terminal oculta en WLANs. Para resolver este problema, se propuso añadir al protocolo de acceso un mecanismo de intercambio de mensajes con reconocimiento positivo el cual se muestra en la figura 2.13. Cuando una estación está lista para transmitir, primero envía una solicitud al punto de acceso (RTS, Request to Send) que incluye una estimación del tiempo que estará ocupando el medio para su transmisión. El AP responde con una autorización (CTS, Clear to Send) con la estimación de tiempo que el canal estará ocupado. Como todas las estaciones remotas escuchan las señales del AP, sabrán que no pueden transmitir durante ese intervalo de tiempo, buscando así evitar las colisiones. Figura 2.13: Mecanismo para evitar colisiones. 2.3.2 Implementaciones El subcomité 802.11 de la IEEE fue creado en septiembre de 1990 con el fin de producir una especificación de red local inalámbrica capaz de fransmitir información a velocidades de entre 1 y 10 Mbps y que pudiese adecuarse a gran cantidad de ambientes, desde extensiones de redes locales basadas en cable hasta conexiones entre pares y automatización industrial y desde transferencia de archivos hasta soporte a con versaciones de voz y control de procesos en tiempo real. El estándar utiliza un modelo de referencia multi capas en el que las capas más bajas corresponden a las especificaciones de capa física y aspectos dependientes del medio particular utilizado (infrarrojo, espectro disperso en la banda de 2.4 GHz y en la de 5 GHz, etc.) La siguiente capa corresponde al protocolo de acceso al medio y es común a todas las redes independientemente del medio físico utilizado, presentando así una visión unificada a las capas superiores. El subcomité 802.11 seleccionó el protocolo DFWMAC (Distributed Foundation Wireless Medium Access Control), como la base del estándar para esta capa. Evolución de la norma IEEE 802.11 Norma Velocidad Banda/Característica 802.11 1 y 2 Mbps 2.4 GHz 802.11b 11 Mbps 2.4 GHz 802.11a 54 Mbps 5 GHz 802.11g 22 y 54 Mbps 2.4 GHz 802.11e 22 Mbps con Calidad de servicio 802.11i Mejoras a mecanismo de seguridad 802.11n 540 Mbps (100-200 Mbps efectivo) 5 y 2.4 GHz La norma permite distinguir entre tráfico de datos y tráfico sensible a retardos, como las conversaciones de voz y sesiones de video. También permite asignar distintas prioridades al tráfico mediante un elegante esquema que permite variar el periodo de espera entre el término de transmisión de una trama y la emisión de la siguiente: Tramas de alta prioridad tendrán un intervalo de espera (IFS, Interframe space) menor que las tramas de prioridad normal. La duración de los intervalos de espera depende de varios factores; entre ellos, la banda de frecuencia y la técnica de modulación. La tabla3{reference-type=ref @ref(t:ifs} muestra los valores típicos para SIFS (para tramas de control), PIFS (tramas prioritarias) y DIFS (tramas de datos sin prioridad): Duración de referencia para los intervalos entre segmentos IFS PHY SIFS PIFS DIFS DSSS 802.11b \\(10\\,\\mu s\\) \\(30\\,\\mu s\\) \\(50\\,\\mu s\\) ERP 802.11g \\(10\\,\\mu s\\) Long=\\(30\\,\\mu s\\) Long=\\(50\\,\\mu s\\) Short=\\(19\\,\\mu s\\) Short=\\(28\\,\\mu s\\) OFDM 802.11a \\(16\\,\\mu s\\) \\(25\\,\\mu s\\) \\(34\\,\\mu s\\) HT 802.11n \\(30\\,\\mu s\\) @ 2.4 GHz Long=\\(20\\,\\mu s\\) @ 2.4 GHz Long=\\(50\\,\\mu s\\) @ 2.4 GHz \\(16\\,\\mu s\\) @ 5 GHz Short=\\(19\\,\\mu s\\) @ 2.4 GHz Short=\\(28\\,\\mu s\\) @ 2.4 GHz \\(25\\,\\mu s\\) @ 5 GHz \\(34\\,\\mu s\\) @ 5 GHz La norma también ha evolucionado para aumentar las tasas de transferencia, operar en distintas bandas de frecuencia y atender los requerimientos de seguridad, entre otros. Las versiones más \\(50\\,\\mu s\\) de esta norma se presentan en la tabla 2{reference-type=ref @ref(t:802.11}. 2.4 Conmutacion Para extender la cobertura de la red, se pueden conectar dos o más redes locales a través de un puente o conmutador. Este dispositivo es capaz de conocer, a partir de sus direcciones MAC, qué estaciones se encuentran en cada uno de sus puertos. Utiliza tablas de conmutación para encaminar tramas únicamente hacia el puerto en el que se encuentra la estación destinataria y filtrar aquéllas que no deben ser encaminadas. De esta forma, el puente o conmutador rompe los dominios de colisión, es decir, los segmentos en los que se puede propagar una colisión entre estaciones, como se muestra en la figura 2.14. Figura 2.14: Una LAN es un dominio de difusión. El conmutador la puede fragmentar en distintos dominios de colisión. Lo anterior resulta en un incremento del desempeño de la red ya que la segmentación de capa 2 reduce el número de estaciones que compiten por el acceso al medio. Es importante notar que los dominios individuales de colisión creados por el conmutador siguen siendo miembros del mismo dominio de difusión, es decir, una trama con dirección destino de difusión (broadcast o multicast) será enviada a todos los puertos (a todos los dominios de colisión). Para propósitos de estas notas, frecuentemente consideraremos una LAN como un dominio de difusión. Eventualmente los costos de la tecnología hicieron posible fabricar conmutadores en los que cada puerto se asigna no a un segmento de red, sino a un dispositivo en particular, como se muestra en la figura 2.15. Así, cada dispositivo tiene un enlace punto a punto a un puerto del conmutador; al no tener que competir por acceder a este medio, las colisiones desaparecen. Debido a que la conmutación se realiza a muy alta velocidad, se pueden tener comunicaciones entre distintos puertos simultáneamente, aumentando de esta manera el desempeño total de la red. Prácticamente todas las redes locales basadas en cableado estructurado han abandonado los concentradores y los servicios de red se habilitan a través de un conmutador. Figura 2.15: Actualmente, la tecnología permite que cada dispositivo pueda asociarse a un puerto en un conmutador. 2.4.1 Principio de operación Los conmutadores a los que nos referimos operan a nivel de la capa de enlace de datos del modelo de referencia OSI. En términos generales, cuentan con una tabla de conmutación que les permite decidir hacia qué puerto encaminar (reenviar) las tramas con base en su dirección destino. Por ejemplo, en la figura2.16, la trama que llega por el puerto 1 tiene como destinatario la dirección @A, que está asociada al puerto 5 en la tabla de conmutación, por lo que trama es encaminada a ese puerto. De manera similar, la trama que entra por el puerto 3, tiene como dirección destino @B que está asociada al puerto 4, hacia donde es encaminada la trama. Figura 2.16: Principio de operación con tablas de conmutación. El tamaño de las tablas de conmutación varía de un fabricante a otro y de un modelo a otro. Representa un criterio importante de diseño sobre todo para redes grandes, con miles de nodos15. Otro criterio a tomar en cuenta, es el mecanismo de conmutación qeu utiliza el dispositivo. Puede dividirse en dos grandes categorías: Store-and-forward y Cut-through. El conmutador Store and forward (figura2.17) espera recibir la trama completa, verifica que los datos no tengan error (verificación del CRC), consulta la tabla de conmutación con la dirección destino y redirige la trama al puerto correspondiente. Figura 2.17: Store and forward. La principal ventaja de este mecanismo es que garantiza la integridad de las tramas, y al detectar una dañada, no lo propaga innecesariamente a otros segmentos. Esto es particularmente útil en redes Ethernet con segmentos compartidos y una carga relativamente alta pues las tramas fragmentadas porque que han colisionado (runt frames), pueden ser detectadas y eliminadas. Otra ventaja importante de este mecanismo, es que puede interconectar redes de diferentes velocidades, aunque para ello se requiere buffers capaces de absorber ráfagas de tramas al acoplar velocidades. Por su parte, los conmutadores Cut-through (figura2.18), también llamados wormhole, no validan la integridad de las tramas cuando cruzan el conmutador. La retransmisión de las tramas se inicia tan pronto se lee la dirección destino. Lo que se busca, por supuesto, es mejorar el desempeño al disminuir el retardo de procesamiento (retardo de conmutación, en este caso) de las tramas. Figura 2.18: Cut-through o wormhole. En los conmutadores Cut-through también se requiere de buffers, pues puede ocurrir que varias tramas tengan que salir a su destino por el mismo puerto, aunque típicamente, el tamaño de los buffers en estos conmutadores es menor que en los Store and forward. 2.4.2 Conmutadores transparentes - operación Los conmutadores a los que nos referimos en este curso se llaman puentes transparentes pues son invisibles a los dispositivos y equipos terminales. Una computadora simplemente coloca una trama en la red y ésta es encaminada a su destino sin que la computadora sepa si para ello tuvieron que participar los conmutadores. Existe otro tipo de conmutadores (típicamente en las redes locales Token Ring) en los que es el dispositivo emisor (la fuente) quien determina la trayectoria que deben recorrer las tramas para llegar a su destino. En los conmutadores transparentes, las tablas de conmutación se crean y actualizan dinámicamente, y con base en ellas, los conmutadores encaminan o descartan las tramas. Un conmutador transparente tiene cuatro funciones: APRENDIZAJE, FILTRADO, REENVÍO, INUNDACIÓN. Para explicarlas, utilizaremos como referencia la red de la figura2.19. Figura 2.19: Red local para describir las funciones de un conmutador Inicialmente, las tablas del conmutador están vacías. La computadora A envía una trama a D. El conmutador revisa la dirección fuente y asocia esta dirección al puerto por donde la recibió, en nuestro caso, el puerto 1. Esta es la función de Aprendizaje (Learning). Las entradas en las tablas tienen una duración determinada (por default, cinco minutos). Cada vez que llega una trama, se actualiza el temporizador; si éste llega a cero, la entrada en la tabla se elimina, garantizando la depuración automática de las tablas de conmutación. La tabla de conmutación hasta ahora estaría como se muestra al lado. Dirección Puerto @A 1 Como el conmutador no conoce en qué puerto se encuentra la computadora D, envía la trama por todos los puertos menos por el que la recibió (Pto2 y Pto 3 en nuestro ejemplo). Esta es la función de Inundación (Flooding). Siempre que reciba una trama para la que se desconoce el destino o cuando el destino sea una dirección de difusión, se efectúa esta inundación. Es de esperar que eventualmente D envíe una respuesta a A. En ese momento, el conmutador vincula la dirección D al puerto 3 (learning) y como encuentra la dirección A asociada al puerto 1, Reenvía (forward) la trama únicamente a ese puerto. Ahora tenemos la tabla que se muestra al lado: Dirección Puerto @A 1 @D 3 Ahora imaginemos que la computadora B le envía una trama a A. Por función de aprendizaje, el conmutador asocia la dirección B al puerto 1 y al consultar la dirección destino, sabe que A también está en el puerto 1 y sencillamente ignora la trama. Esta es la función de Fitrado (Filtering). La tabla de conmutación queda así: Dirección Puerto @A 1 @B 1 @D 3 Esta función de filtrado es la que permite expandir la cobertura de la red local que se mencionó al inicio de esta sección y aumentar el desempeño de la red. El tráfico local queda aislado en su propio dominio de colisión y sólo es reenviado a otro segmento (a otro dominio de colisión) cuando es estrictamente necesario. Para finalizar, podemos sintetizar la operación de un conmutador transparente en el diagrama de flujo de la figura2.20. Figura 2.20: Operación de un puente (o conmutador) transparente 2.5 Protocolo Spanning Tree En las redes empresariales, es muy importante tener equipos redundantes y rutas alternas para mantener la continuidad de la operación en caso de fallos. Por ejemplo, la figura2.21 muestra topología genérica de una red local de una organización. Se pueden notar enlaces redundantes en todos los conmutadores. Figura 2.21: Topología con enlaces y conmutadores redundantes Sin embargo, por la forma en que operan los conmutadores, esto genera un severo problema conocido como de lazos activos o tormenta de tramas. Es un problema que ocurre naturalmente en las tramas de difusión, pero también puede ocurrir con tramas dirigidas a un solo destinatario (tramas unicast). Lazos activos en trama de difusión En la imagen de la izquierda de la figura?? se presenta el efecto de la tormenta de tramas de difusión. Los dos conmutadores están conectados a los segmentos donde se encuentran las computadoras Nodo A (segmento 1) y Nodo B (segmento 2), generando un lazo o bucle en la topología. Suponga que A emite una trama de difusión (dirección destino FF-FF-FF-FF-FF). La trama de difusión se propaga por el segmento 1 y es procesada por los conmutadores sw1 y sw2. Dado que se trata de una trama de difusión, cada uno la reenviará al segmento 2 por sus respectivos puertos Pto2. Ahora tenemos dos tramas de difusión en el segmento 2. La trama emitida por sw1 en su puerto Pto2 es tomada por sw2 (en su puerto Pto2) y, como es una trama de difusión, sw2 la reenvía al segmento 1, donde sw1 la vuelve a recibir por su puerto Pto1 y la reenvía al segmento 2. Lo mismo ocurre con la trama emitida por sw2 en el segmento 2, que es tomada por sw1 y reenviada al segmento 1. Tenemos dos tramas circulando indefinidamente por los dos segmentos. Esta es la tormenta de tramas. En la figura?? sólo se muestran dos conmutadores. En una red realista como la de la figura2.21, donde hay múltiples lazos, estas tormentas de tramas dejan a la red completamente congestionada e inoperable en unos cuantos segundos. Figura 2.22: El problema de lazos activos. (a) Tormenta de tramas broadcast; (b) Tormenta de tramas unicast Lazos activos con tramas unicast. En la imagen de la derecha de la figura figura?? se muestra cómo se genera una tormenta de tramas unicast. El nodo A envía una trama hacia el nodo B la cual se difunde en el segmento 1. Tanto sw1 como sw2 reciben la trama y revisan la dirección destino. Asumiendo que la tabla de conmutación está vacía, los dos conmutadores asocian la dirección de A a su respectivo puerto Pto1 y realizan la función de inundación, reenviando cada uno la trama al segmento 2. Ahora inicia la tormenta de tramas: sw2 recibe por su Pto2, la trama reenviada por sw1 (y, por supuesto, sw1 recibe la enviada por sw2). Como no tiene registrada la dirección de B, toma esa trama y la envía nuevamente al segmento 1, pero además, ahora sw2 asume que el nodo A está en el segmento 2 pues desde ese segmento recibe una trama con dirección fuente A, por lo que actualiza su tabla de conmutación. ¡Lo mismo ocurre con sw1 al recibir la trama enviada por sw2 en el segmento 2! Esta actualización de las tablas también ocurre con las tramas de difusión. Hay un efecto adicional. Si B responde y por casualidad las tablas de conmutación tienen la dirección A asociada correctamente al segmento 1, tendremos una red con tramas duplicadas, pero al menos se estabiliza la tormenta de tramas. Si B responde y por casualidad la dirección A está asociada a los Pto2 (al segmento 2), esa trama será filtrada por los dos conmutadores y la comunicación entre A y B no tendrá lugar. Pero si B no está disponible (por ejemplo, porque está apagado, desconectado de la red, o simplemente la dirección destino es errónea), la tormenta de tramas duplicadas por sw1 y sw2 se mantendrá indefinidamente. 2.5.1 Protocolo Spanning Tree Para resolver el problema de lazos activos, se implementa en los conmutadores un algoritmo llamado Spanning Tree (árbol expandido) el cual tiene como objetivo el que exista un único camino activo entre dos segmentos cualquiera. El algoritmo fue estandarizado en la norma IEEE 802.1D y actualizado en la norma IEEE 802.1t. Los conmutadores (o puentes) intercambian mensajes entre sí para crear una una topología lógica libre de ciclos en la red local. La trayectoria creada busca ser óptima con base en un criterio de costo que se relaciona con la velocidad de las interfaces de red. El protocolo hace que las trayectorias redundantes estén desactivadas hasta que se detecta un problema. Si ocurre, la topología lógica se reconfigura para crear trayectorias alternas. Los conmutadores intercambian mensajes conocidos como BPDU, Bridge Protocol Data Unit. Son tramas LLC con identificador SAP 0x42 enviadas a la dirección de difusión restringida 01-80-c2-00-00-00. El protocolo Spanning Tree basa gran parte de su operación en dos conceptos: Identificador del Puente (BID, Bridge Id) y Costo de la Trayectoria. El BID es un valor de 8 bytes compuesto por un campo de Prioridad de 2 bytes (rango de 0 a 65,535, con valor por omisión de 32,768) y un campo de 6 bytes obtenido de la dirección MAC del conmutador (generalmente tomado del backplane o de la tarjeta de administración). Ver figura2.23. Figura 2.23: Formato del Bridge Id, BID* En la norma IEEE 802.1t se establece que los 12 bits menos significativos del campo de prioridad tienen valor 0, por lo que los valores de Prioridad se dan en incrementos de 4,096. Esto quiere decir que solamente se tienen 16 valores posibles de Prioridad. El costo de la trayectoria se calcula como la suma del costo de los enlaces para llegar a un conmutador particular llamado el Puente Raíz. A cada puerto se le asigna un costo que depende de su velocidad de transmisión. En la norma 802.1D se recomendaba calcular el costo como 1000 Mbps dividido por la capacidad del enlace; sin embargo, con el surgimeiento de redes de Gbps se observó que esta regla pronto sería obsoleta. La norma IEEE 802.1t recomienda dividir 20 Tbps entre la capacidad, como se muestra en la tabla siguiente: Costos sugeridos para los puertos en STP Velocidad 802.1D 802.1t 4 Mbps 250 - 10 Mbps 100 2,000,000 16 Mbps 62  100 Mbps 19 200,000 1 Gbps 4 20,000 10 Gbps 2 2,000 100 Gbps  200 1 Tbps  20 10 Tbps  2 El administrador de la red puede utilizar cualquiera de las normas o elegir otros criterios y otros valores. Sin embargo, es MUY IMPORTANTE que sea consistente y configure los mismos valores en todos los conmutadores de la red; de lo contrario, se crearán topologías sumamente ineficientes. Se debe tener especial cuidado al desplegar y administrar redes que tienen equipos de distintos fabricantes (como Cisco, Huawei, Extreme, Juniper) pues los costos por omisión que éstos asignan a sus equipos suelen ser distintos. Establecimiento de la topología Como se ha mencionado, lo que se busca es establecer una topología de costo mínimo y libre de lazos para llegar a un nodo particular (el Puente Raíz). La métrica de costo es la velocidad de los enlaces. Antes de explicar cómo funciona el protocolo debemos definir algunos conceptos: Puente raíz. Es el conmutador a partir del cual se construye la topología lógica. Se elige como aquél que tiene el menor BID. Puerto raíz. Es el puerto en un conmutador que lo conecta al puente raíz por la mejor trayectoria (la de menor costo). Puente designado. Si a un segmento están conectados varios conmutadores (lo cual es de esperar, pues es precisamente por eso que se pueden formar lazos en la topología), el puente designado es el encargado de encaminar las tramas hacia y desde el puente raíz. Puerto designado. Es el puerto del puente designado que encamina las tramas del segmento. Se trata del puerto con el menor costo hacia la raíz. Puerto bloqueado. Son los otros puertos en un segmento que no encaminan tramas, pero pueden escuchar BPDUs para reconfigurar la topología en caso de fallos. Para establecer la topología, los conmutadores intercambian las tramas BPDU que pueden ser de dos tipos: Configuración y TCN (Topology Change Notification). Las BPDU tienen muchos campos; por ahora únicamente nos concentraremos en los cuatro que se muestran en la figura2.23: El BID del puente raíz, el costo para llegar a la raíz, el BID del conmutador que la emite y el identificador del puerto donde se emitió: Figura 2.24: Formato del Los campos más importantes de una BPDU* La topología se establece en tres pasos: Selección del puente raíz; selección de los puertos raíz; selección de los puertos designados. Los puertos que no son raíz ni designados, quedan bloqueados. Para ejemplificar el protocolo, utilizaremos la pequeña red que se muestra en la figura2.25. Todos los enlaces son FastEthernet (100 Mbps) y supondremos una tabla de costos 802.1D; es decir, los enlaces tienen un costo de 19. Figura 2.25: Red para ejemplificar STP 1. Selección del puente raíz El primer paso es seleccionar el puente raíz, el cual será el puente a partir de donde se formarán las ramas del árbol. Al inicio, cada conmutador se considera el puente raíz y envía por todos los puertos una BPDU con el BID de raíz igual a su propio ID y con un costo de 0 para llegar a la raíz. Por ejemplo, Sw3 enviará una BPDU como la siguiente por sus puertos Pto1 y Pto2: Sw1 recibe las BPDU de Sw2 y Sw3, compara los BID con el propio, y concluye que él es la raíz. De forma similar, cuando Sw2 y Sw3 reciben las BPDU de Sw1 ambos concluyen que no son la raíz, dejan de emitir BPDUs por el puerto por el que recibieron la notificación de un mejor candidato raíz y efectúan el siguiente paso: Selección de los puertos raíz. 2. Selección de los puertos Todos los conmutadores menos la raíz, deben seleccionar uno de sus puertos como el puerto raíz. Se elige el puerto que tenga el costo menor (a veces llamado distancia menor) a la raíz. Observe la figura2.26. Figura 2.26: Selección del puerto raíz. El puente raíz (Sw1) emite periódicamente BPDUs con un costo igual a 0. Los conmutadores 2 y 3 reciben estas BPDU por sus respectivos Pto1 en una interfaz FastEthernet, por lo que suman el costo correspondiente (19) y generan una BPDU con ese costo y la emiten por sus respectivos Pto2. Por ejemplo, la BPDU emitida por Sw2 es la siguiente: Cuando Sw3 recibe esta trama, le suma el costo de la interfaz y estima que llegar a la raíz por su Pto2 tiene un costo de 38, mientras que por su Pto1 el costo es de 19. Por ello, selecciona Pto1 como su puerto raíz. Lo mismo hace Sw2 con la BPDU que recibió de Sw3 y elige como raíz su propio Pto1. 3. Selección de los Puertos Designados Finalmente, los conmutadores seleccionan los puertos designados. Los puertos designados son aquellos que en operación normal están habilitados, es decir, reenvían tramas. Solo podrá existir un puerto designado por cada segmento. Todos los conmutadores que no tengan su puerto designado para un determinado segmento, pondrán sus puertos en estado de bloqueo para operación normal, sin embargo, sí reciben BPDUs para poder participar en una reconfiguración de la topología en caso de ser necesario. Para definir qué conmutador es el designado en el segmento 3, hay un intercambio de BPDUs entre los conmutadores 2 y 3 en ese segmento. Como ambos BPDUs tienen el mismo costo hacia el puente raíz, entonces se utiliza el segundo criterio de desempate, que es el conmutador con el menor BID. En nuestro ejemplo, el conmutador 2 es seleccionado y habilita su puerto 2, mientras que el conmutador 3 bloquea su puerto 2, con lo que la topología lógica resultante es la que se muestra en la figura2.27. El conmutador 3 sigue recibiendo BPDUs por su puerto bloqueado; en el momento en que deja de recibir dichos BPDUs, habilita su puerto, proporcionando de esta manera la redundancia esperada. Figura 2.27: Topología lógica resultante Es posible que dos puertos en el mismo conmutador tengan el mismo costo a la raíz. El ejemplo más común es cuando se tienen enlaces redundantes de igual velocidad a la raíz (a otro conmutador en la trayectoria hacia la raíz) como se muestra en la figura2.30. En este caso, para definir al puerto designado se aplica un tercer criterio de desempate, que es el Identificador de Puerto: el puerto con el menor identificador será el puerto designado. Cabe mencionar que las interfaces de los conmutadores también tienen un valor de prioridad, que es 128 por omisión. Si un administrador desea asegurar que un puerto particular sea el puerto designado, puede disminuir ese valor de prioridad, asegurando así que tendrá el valor menor. Asignación del Puente Raíz En redes locales de mediana complejidad, es importante que el administrador tenga la posibilidad de establecer cuál es el puente raíz, lo que se consigue modificando el campo de prioridad en el BID. Como a partir de él se genera la topología, debe ser un muy robusto (por ejemplo, con redundancia en las fuentes de alimentación de corriente) y con una alta velocidad de conmutación. Además, puede tener un impacto importante en el diámentro de la red, es decir, la distancia máxima entre dos segmentos en la red local, como se muestra en la figura2.28. Figura 2.28: La importancia de poder elegir el puente raíz. En la primer topología vemos una arquitectura de conmutadores con múltiples trayectorias entre dos conmutadores cualesquiera. El segundo diagrama muestra la topología lógica del Spanning Tree si el conmutador 4 fuera el puente raíz. Al estar más o menos al centro de la red, el díametro de ésta es pequeño. El último diagrama muestra qué pasaría si el conmutador Sw1 fuera el puente raíz: la comunicación entre nodos casi vecinos (ej. A y B) tendría que recorrer prácticamente todos los conmutadores de la red. Aunque las versiones modernas de STP soportan conmutadores raíz redundantes, una configuración apropiada de los valores de prioridad en cada uno de los conmutadores permite establecer cuáles serían los conmutadores de respaldo en caso de que el puente raíz seleccionado falle. Temporizadores y reconfiguración de la topología La configuración y mantenimiento de la topología en Spanning Tree está controlada por tres temporizadores que determinan el estado de los puertos y el envío de las BPDU. Estos son: Hello Time. Determina el intervalo de tiempo de envío de BPDUs de configuración desde la raíz. La norma 802.1D sugiere un valor por omisión de 2 segundos; puede tomar valores de 1 a 10 segundos. Forward Delay. Es el tiempo en que un puerto permanece en los estados de Listening y Learning (ver más adelante). El valor por omisión es de 15 segundos y puede tomar valores en el rango 4 a 30 segundos. Max Age. Es el tiempo que un puente almacena una BPDU antes de descartarla. Cada puerto guarda una copia de la mejor BPDU que ha recibido. Si ésta no se refresca después de Max Age segundos, la copia se descarta y el conmutador asume que ha habido un cambio en la topología, por lo que el protocolo STP debe reactivarse. El valor por omisión es de 20 segundos y puede ser configurado en el rango 6 a 40 segundos. Se tiene un cuarto parámentro relacionado con los temporizadores: Message age. Pretende estimar el tiempo transcurrido desde que la BPDU se emitió por el puente raíz. En realidad, la BPDU parte de la raíz con un valor 0 y se incrementa por cada conmutador que atraviesa. Así, este campo indica qué tan lejos se está de la raíz. Los valores por omisión fueron estimados considerando una red con un diámetro máximo de siete conmutadores. Es muy importante no cambiarlos, o cambiarlos exactamente igual en todos los conmutadores; de lo contrario, se puede provocar una pérdida de sincronía entre los puentes. Los puertos pueden estar en alguno de los cinco estados que se muestran en la figura2.29. Figura 2.29: Diagrama de estados de los puertos en STP. Un puerto inicia deshabilitado hasta que se active el protocolo o porque se considera no operacional. En este estado, no es capaz de reenviar tramas ni de recibir BPDUs. Al activar STP, los puertos del conmutador pasan al estado Blocking durante el proceso de elección del puente raíz. Como se ha comentado, también pasan a este estado si no son puerto raíz o puerto designado. Un puerto bloqueado no reenvía tramas pero sí escucha BPDUs. Después de un tiempo (20 segundos por omisión) de no recibir BPDUs, pasa al estado Listening. Llegan al estado Listening los puertos raíz y puerto designado. Los demás quedan en Blocked (a menos que dejen de escuchar BPDUs). En este estado el puerto descarta todas las tramas: tanto las que recibe del segmento, como las que recibe de otros puertos. Sólo escucha BPDUs. Este estado ofrece un tiempo de estabilización para evitar entrar en configuraciones innecesarias. Por omisión, los puertos permanecen en este estado durante 15 segundos. Posteriormente, el puerto pasa a Learning. El puerto escucha las tramas en el segmento para actualizar la tabla de conmutación, pero todavía no reenvía tramas. Esto permite evitar inundación innecesaria de tramas. También escucha y procesa BPDUs. Permanece en este estado 15 segundos por omisión. Finalmente, el puerto llega a estado Forwarding en el que realiza las funciones normales de reenvío, filtrado, inundación y aprendizaje que se presentaron al inicio de esta sección. Si bien los cambios en la topología no son muy frecuentes, esta es una de las principales críticas del protocolo Spanning Tree 802.1D: Cuando se da un cambio en la topología, la reconfiguración de un puerto tarda al menos 50 segundos: 20 para salir de Blocking, 15 en Listening y 15 en Learning. Como veremos más adelante, Rapid STP permite reconfiguraciones en un tiempo mucho menor. La trama BPDU Para terminar esta sección veamos los campos de una trama BPDU. Podemos considerar que está formada por tres secciones: Características del protocolo PID. Identificador del protocolo. 2 Bytes, tiene un valor de 0x0000 para STP 802.1D PIV. Versión. 1 Byte, tiene un valor 0x00 Message type. 1 Byte, tipo de BPDU: Configuration o TCN (Topology change notificaton) Flags. 1 Byte, sólo es relevante para tramas TCN e indica si es una notificación de cambio (TCN) o un acuse de recepción (TCA) Campos STP Root ID. BID del puente raíz. 8 Bytes: 2 de prioridad y 6 de su dirección MAC Root Path Cost. 4 Bytes, costo de la trayectoria para llegar a la raíz a través de ese puerto. Bridge ID. BID del emisor. 8 Bytes: 2 de prioridad y 6 de su dirección MAC Port ID. Identificador del puerto por el que se emitió la BPDU. 2 Bytes Temporizadores Message Age 2 Bytes Maximum Age 2 Bytes Hello Time 2 Bytes Forward Delay 2 Bytes 2.6 Rapid STP Como se ha mencionado anteriormente, el tiempo de convergencia, es decir, el tiempo en el que se estabiliza la red en caso de que la topología deba reconfigurarse, es demasiado grande en Spanning Tree: de 30 a 50 segundos. Rapid Spanning Tree, definido en la norma IEEE 802.1w permite una convergencia mucho más rápida: típicamente de 6 segundos en caso de que falle el puente raíz, y de unos cuantos milisegundos en caso de que que falle algún enlace. Por una parte, se asume una falla en el puente raíz si no se han recibido BPDUs después de 3 Hello times. Como este temporizador tiene un valor por omisión de 2 segundos, a los 6 segundos se inicia el proceso de reconfiguración. Por otra parte, se eliminan los estados Blocked y Listening. Los puertos están en Discarding o en Learning, para pasar muy rápidamente a Forwarding. Además, los puertos que no están en Forwarding (los bloqueados) pueden tener dos roles: Backup y Alternate. En el primero, en cuanto se detecta un fallo en el puerto designado, el de respaldo toma su lugar. El segundo indica una ruta alternativa para llegar a la raíz. Finalmente, los conmutadores no solamente reenvían BPDUs raiz (con un ajuste de costo). Al dejar de recibir los de la raíz, ellos pueden generar sus propios BPDUs proposal proponiéndose como raíz en vez de esperar los 30 segundos de STP. Si el vecino acepta la propuesta, responde con un agreement. En estos casos, las tablas de conmutación se borran de inmediato, por eso los puertos pasan de Discarding a Learning. 2.7 Agregación de enlaces El protocolo Spanning Tree evita la creación de lazos, pero esto tiene un efecto secundario indeseable. Considere la red de la figura2.30. Si entre los dos conmutadores hay un solo enlace de 1 Gbps pero éste resulta insuficiente para soportar la carga de tramas intercambiada entre los equipos conectados a ellos, con STP la única alternativa es cambiar el enlace de 1 Gbps por uno de 10 Gbps. Esto excede las necesidades de la red, pero sobre todo, puede resultar demasiado costoso. Figura 2.30: Topología con cuatro enlaces redundantes entre conmutadores Es posible que los conmutadores tengan otros puertos de 1 Gbps libres y sería atractivo poner enlaces adicionales como los que se muestran en la figura para ofrecer una capacidad de 4 Gbps. Sin embargo, STP vería estos enlaces como redundantes que crean lazos entre los dos conmutadores, por lo que bloquearía tres de ellos y dejaría activo sólo uno. La norma IEEE 802.3ad (posteriormente integrado a la norma 802.1AX) define el protocolo Link Aggregation Control Protocol para que los cuatro enlaces físicos sean agrupados y vistos como uno solo lógico por STP. A este concepto de agregación también se le conoce como trunking, bundling, bonding o teaming por distintos fabricantes. La agregación de los enlaces sólo es válida bajo varias condiciones, por ejemplo: Todos los enlaces deben ser de la misma velocidad Deben ser enlaces dedicados La agregación sólo se permite para un número pequeño de enlaces, típicamente 2 a 8 Para algunos fabricantes, sólo se permite agregar enlaces que estén en puertos contiguos y en la misma tarjeta. La dirección MAC de la interfaz lógica puede ser configurada manualmente o de manera automática, en cuyo caso se toma la dirección más pequeña de los enlaces agrupados. El balanceo de carga entre los enlaces también es configurable. Puede establecerse que los paquetes de un mismo flujo (misma fuente y mismo destino, entre otros criterios) siempre salgan por el mismo enlace, o que los paquetes se distribuyan secuencialmente (en round robin) entre los enlaces. LACP fue establecido después de que la mayoría de los principales fabricantes ya habían desplegado soluciones propietarias similares. Por ello, se tienen muchas restricciones al integrar este mecanismo entre equipos de distintos fabricantes. 2.8 Redes locales virtuales En la sección anterior se mostró que los conmutadores ofrecen muchas ventajas a las redes locales; la más notable, el aumento en el desempeño al aislar los segmentos compartidos de red, es decir, al romper los dominios de colisión. Sin embargo, siguen presentando algunas limitaciones sobre todo conforme va creciendo el número de equipos conectados a la red local (lo cual, es lógico que ocurra pues en las redes conmutadas ya no tenemos las limitaciones de diámetro inherentes al protocolo CSMA/CD en los segmentos compartidos). En primer lugar sigue habiendo un problema de desempeño de la red local pues si bien los puertos de un conmutador aíslan los dominios de colisión, toda la red local forma un solo dominio de difusión. Efectivamente, recordemos que cuando se recibe una trama con una dirección destino de difusión (multicast o broadcast), ésta se reenvía a todos los demás puertos (lo que llamamos inundación en la sección anterior). Desgraciadamente, son muchos los protocolos de red que utilizan tramas de difusión: STP es uno de ellos y más adelante en el curso conoceremos otros. En segundo lugar, se mantiene un problema de seguridad. Aunque en principio si cada computadora puede estar conectada a su propio puerto y desaparecen, o disminuyen drásticamente los segmentos compartidos en los que un usuario malintencionado puede instalar un analizador de protocolos para observar el tráfico en la red, el hecho es que ese usuario podrá recibir todas las tramas de difusión, conocer la dirección MAC de las computadoras que las generaron, y posteriormente dirigir tramas hacia ellas, con la intención de explotar alguna vulnerabilidad. Esto es así porque los conmutadores no tienen ningún mecanismo de filtrado; simplemnte descartan o reenvían tramas con base en su tabla de conmutación. Por otra parte, tenemos un problema de flexibilidad y de gestión de la red, pues nuestra concepción de red local está relacionada con la conexión física de un dispositivo a un conmutador. Por ejemplo, la computadora de Ana, que se encuentra en el cubículo 2 del piso 1 del edificio 3, está asociada a la red de ese edificio (o piso) y está conectada al puerto 10 del conmutador Sw1. En esa misma red local están conectados algunos servidores (como los servidores de archivos y de autenticación) que Ana accede regularmente. Si por alguna razón Ana tiene que moverse de su oficina (quizás porque están reparando su cubículo o simplemente porque es convocada a una reunión de trabajo en una sala de juntas) y se lleva su computadora, digamos, al piso 2 del edificio 1, Ana estaría conectando su computadora a otra red, sin la posibilidad de acceder a sus servidores de archivos a menos que se tenga la tecnología que permita la interconexión de redes, lo cual será tratado brevemente más adelante y a gran profundidad en el capítulosiguiente. Las redes conmutadas de gran escala presentan muchos otros problemas, pero con los expuestos hasta ahora es suficiente para justificar la aparición de las Redes de Área Local Virtuales, VLANs, Virtual Local Area Networks. Una VLAN es una agrupación lógica de dispositivos en una misma infraestructura de red local. Es decir, permite crear redes que son virtualmente independientes entre sí (cada red es un dominio de difusión independiente) aunque se encuentren en la misma red física (los dispositivos conectados a distintos puertos de los mismos conmutadores). Por ejemplo, en la red de la figura2.31, todas las computadoras y servidores están físicamente conectados a la misma red local, pero con el mecanismo de VLANs, podemos aislar los dispositivos en tres redes diferentes (identificadas por el color en la figura), como se muestra en la imagen de la izquierda. Figura 2.31: El concepto de VLAN: (a) Topología física; (b) Topología lógica Con la segmentación por VLANs, las tramas de difusión generadas por los dispositivos de una VLAN, por ejemplo la VLAN azul, sólo serán visibles por los dispositivos de ESA VLAN. Los nodos de las otras VLAN nunca recibirán esas tramas. Al mismo tiempo, no hay forma de que una computadora de la red amarilla pueda acceder al servidor (o a otras computadoras) de las redes roja y azul, a menos que exista un enrutador (o un conmutador capa 3) y la configuración necesaria para enrutar tráfico entre ellas. 2.8.1 Criterios de membresía En una VLAN la comunicación solo puede darse entre los usuarios y servicios que pertenecen a la misma VLAN. De esta manera, el administrador de la red puede definir qué usuarios tienen acceso a qué recursos. Los criterios de membresía son los mecanismos con los que se puede configurar la pertenencia de un dispositivo a una VLAN determinada. Entre los más comunes se tienen: Generación 1 (básicos) 1. Puerto 2. Dirección MAC Generación 2 (conectividad) 3. Protocolo de capa superior 4. Dirección de red Generación 3 (aplicación) 5. Dirección multicast 6. Definido por el usuario Generación 4 (seguridad) 7. Autenticación (Acceso y Auditoría) En la práctica, los criterios pueden combinarse de tal forma que a una VLAN puedan pertenecer múltiples nodos que han cumplido con diversas reglas o políticas. Sin embargo, hay que tener cuidado al combinar las reglas para asegurar que los dispositivos quedan asociados únicamente a las VLAN autorizadas. VLAN por puerto Esta es la forma más sencilla de definir un criterio de membresía: Los puertos del conmutador se asocian a una determinada VLAN (o, como veremos más adelante, a la VLAN1 por omisión) y los dispositivos que se conectan a ese puerto se asocian a la VLAN correspondiente, como se observa en la imagen izquierda de la figura2.32 en la que se representan dos VLAN: la azul y la roja. Si bien esta forma de determinar la membresía es muy sencilla, resulta muy laboriosa y propensa a errores al implementarla en redes de tamaño medio pues por un lado, la configuración de los puertos debe hacerse de forma manual, y por el otro, debe tenerse mucho cuidado de conectar el dispostivo al puerto apropiado. Cabe resaltar en la figura que si en alguna parte de la red se tienen segmentos compartidos (representados por los concentradores del lado izquierdo), en principio todas las computadoras en ese segmento deben pertenecer a la misma VLAN, pues el concentrador está conectado a un puerto específico en el conmutador. Enfatizamos en principio ya que es posible que ese puerto sea de trunking y que las computadoras en el segmento compartido tengan capacidad de etiquetado. Observe los conmutadores al centro de la red. Están conectados a los conmutadores en la periferia por un puerto determinado que debe ser capaz enviar y recibir tramas de varias VLAN distintas. Estos son los puertos llamados troncales o de trunking. Cuando se recibe una trama de difusión o con una dirección fuente todavía no registrada en las tablas de conmutación, el conmutador debe saber a qué puertos reenviarla: A aquellos donde hay dispositivos que pertenecen a la misma VLAN. Por ello, es necesario que las tramas tengan un identificador o etiqueta de la VLAN a la que pertenecen. En un momento profundizaremos en este tema. Por ahora, es importante señalar que el proceso de etiquetado típicamente ocurre en los conmutadores, y los dispositivos terminales lo desconocen por completo. Figura 2.32: Criterios de membresía: (a) VLAN por puerto; (b) VLAN por dirección MAC. VLAN por MAC En estas VLAN, el administrador de la red define el conjunto de direcciones MAC asignadas a cada VLAN. Este criterio de membresía ofrece un enorme grado de seguridad pues sabemos que las direcciones MAC son únicas universalmente16 Este criterio de membresía ofrece mucho mayor libertad de movimiento, es decir de poder conectar cualquier equipo a cualquier puerto en cualquier conmutador de la red. Sin embargo la configuración es sumamente molesta y propensa a errores, pues hay que introducir las direcciones MAC manualmente. Adicionalmente, resta flexibilidad a los usuarios, pues si éstos cambian de equipo (lo que ocurre con creciente frecuencia con el uso de laptops y notebooks), ya no tendrán acceso a la red hasta que el administrador registre la nueva dirección MAC. VLAN por protocolo Este tipo de membresía permite al administrador agrupar los nodos con base en el tipo de protocolo de capa superior (típicamente, capa de red) definido en la trama (ver imagen izquierda de la figura2.33). Permite la separación lógica de los protocolos para que aquellos protocolos orientados a difusión no afecten a toda la red. Las VLAN definidas por protocolo son efectivas para pilas de redes como IP o SNA (protocolo propietario de IBM), pero no para protocolos que no definen subredes como por ejemplo NetBIOS. VLAN por subred En redes que utilizan la pila de protocolos TCP/IP, como es la dominante mayoría de las redes en la actualidad, este criterio de membresía es el más utilizado. Es un tipo de VLAN muy flexible y fácil de administrar: Al momento de asignar las direcciones de red (las direcciones IP), lo cual típicamente se hace con una política organizacional, el dispositivo queda vinculado a la VLAN que le corresponde, como se muestra en la imagen derecha de la figura2.33. A pesar de que el conmutador ve la información de capa 3 para su asignación a la correspondiente VLAN, la transferencia de información se sigue haciendo a nivel de la capa 2. Figura 2.33: Criterios de membresía: (a) VLAN por protocolo; (b) VLAN por subred. VLAN autenticadas Las VLAN autenticadas proveen un alto nivel de seguridad requiriendo a los usuarios que se identifiquen (autentiquen) ante un servidor para ganar acceso a los recursos de la red. Con base en la autenticación, el servidor asignará el dispositivo a una VLAN determinada, lo que limita el acceso a los recursos de la organización. Adicionalmente, es frecuentemente que se monitoree la actividad del usuario al acceder a esos recursos, cumpliendo con las funciones de seguridad AAA (Authentication, Authorization, Accounting). De manera muy sencilla, el proceso es el siguiente: Los puertos del conmutador son configurados para autenticación El cliente solicita una petición segura de ingreso mediante un login El conmutador reenvía la petición a un servidor de autenticación (Radius, LDAP, etc.) El servidor autentica y autoriza avisando al conmutador a qué VLAN debe asociarse el dispositivo El conmutador asigna al cliente a la VLAN correspondiente (etiqueta su tramas con el valor que corresponda) Criterios para asignación Los criterios para decidir qué usuarios (o sus dispositivos) deben asociarse una VLAN determinada, dependen de las políticas de la organización, pero en términos generales suelen distinguirse dos grupos: Una asociación con base en las áreas funcionales, o bien con base en los servicios de red. En el primer caso, se define una VLAN para cada área funcional o unidad de negocio (por ejemplo, ventas, contabilidad, recursos humanos). Como es frecuente que el personal en estas unidades de negocio esté físicamente en un área cercana, a estas políticas de asignación también se les llama VLAN por infraestructura. Cada unidad funcional tiene acceso a sus propios servidores. Por supuesto, se presenta una situación en la que los empleados de distintas VLAN deben acceder a los servidores institucionales (por ejemplo el servidor de correo o de Web). En estos casos, esos servidores estáran conectados a puertos de trunking que acepten el envío de tramas de las distintas VLAN que han sido definidas. Los criterios de asignación por servicios de red son menos frecuentes y requieren de herramientas de gestión más sofisticadas, pero ofrecen un mejor control qué usuarios pueden acceder a qué recursos. Aquí, los usuarios pertenecen a múltiples VLANs: aquellas para las que las políticas de la organización le dan acceso. Bajo este esquema el administrador puede asignar niveles de servicio a cada usuario, bloquear servicios e incluso establecer esquemas de tarificación por acceso. Como podrá haberlo deducido, las VLAN autenticadas son un buen ejemplo de políticas de asignación basadas en servicios. 2.8.2 Etiquetado de VLAN Los primeros mecanismos para el despliegue de VLANs eran propietarios e incompatibles entre sí. Esto acarreaba muchísimos problemas de gestión y creaba dependencias con los proveedores. Todo esto se corrigió con el surgimiento del protocolo IEEE 802.1Q, a veces llamado 802.1p/Q para enfatizar que en esta norma también se incluye un esquema de priorización de tramas. Como se muestra en la figura2.34, esta norma agrega un campo de 4 octetos a la trama Ethernet entre la dirección fuente y el tipo de protocolo para indicar con un identificador de VLAN, entre otros campos, la VLAN a la que pertenece la trama. Observe que las tramas Ethernet con etiqueta de VLAN pueden violar las restricciones de tamaño máximo de trama. Efectivamente, una trama etiquetada, puede alcanzar un tamaño máximo de 1,522 bytes. Algunos dispositivos viejos pueden rechazar estar tramas. En este caso, las capas superiores deben asegurarse de enviar segmentos de datos no mayores a 1,496 bytes. La mayoría de los conmutadores modernos aceptarán estas tramas, y, de hecho, la norma IEEE 802.3 modifica el tamaño máximo de tramas Ethernet a 1,522 bytes. Figura 2.34: Etiquetado de VLAN 802.1D Los primeros dos bytes contienen el campo TPID (Tag protocol Identifier), que tiene el valor 0x8100 y sirve para indicar a los conmutadores que esta trama tiene una etiqueta de VLAN. Se han registrado otros TPID, como 0x88ad (en IEEE 802.1ad) para VLANs apiladas, y 0x9100 (propietario), los cuales rebasan el alcance de estas notas. Los siguientes dos bytes contienen el TCI (Tag Control Information) formado a su vez por tres campos: Priority code point. Es un campo de tres bits que permite mapear clases de servicio (un concepto que trataremos en el capítulo de Calidad de Servicio) con hasta ocho niveles de prioridad, siguiendo los lineamientos del grupo de trabajo IEEE 802.1p. Drop Eligible Indicator. Es un campo de un bit que indica aquellas tramas que son elegibles a descartar en caso de congestión. Este concepto también será tratado en el capítulo de Calidad de Servicio. Anteriormente, este campo se conocía como canónico y trataba de facilitar la integración de redes Token Ring y Ethernet. En términos generales, si el campo tenía un valor 1, indicaba una que en el campo de datos había información adicional relacionada con el enrutamiento fuente que se utiliza en Token Ring. VLAN identifier. Los últimos 12 bits corresponden a la etiqueta o identificador de VLAN, lo que permite identificar hasta 4,096 VLANs, aunque algunos valores (0x000, 0xFFF) están reservados. La etiqueta 0x000 indica que en realidad no se tiene un VID pero los campos PCP y DEI son válidos. Es decir, este valor se utiliza para asignar una prioridad a tramas que no están asociadas a una VLAN en particular. Se le conoce como priority tag. La etiqueta 0x001 es la etiqueta por omisión. Debe tratarse con cuidado pues si bien la mayoría de los fabricantes asignan todos los dispositivos a la VLAN1, otros lo asignan a tráfico de gestión de la red. Los 4,093 identificadores restantes, se pueden utilizar libremente. Sin embargo, en la práctica existen muchos conmutadores de gama media y baja que soportan un número mucho más reducido de VLANs. 2.8.3 Puertos de acceso y de trunking En un conmutador que soporta VLANs, todos los puertos tienen un identificador de VLAN (PVID) que es VLAN1 por omisión. El administrador de la red configura los puertos con el PVID correspondiente al configurar las VLAN. Independientemente de su PVID, los puertos pueden ser de acceso o de trunking. Puertos de acceso Normalmente, el tráfico generado (y recibido) por los equipos terminales, no tiene y no puede gestionar el campo de etiqueta de VLAN; sólo envía y recibe tramas Ethernet (o IEEE 802.3) ordinarias. Estos dispositivos se conectan a un puerto de acceso. Cuando el puerto recibe una trama sin etiquetar, agrega a la trama el campo de etiqueta con el VID del puerto. De forma similar, cuando debe enviar una trama etiquetada, retira la etiqueta y entrega una trama Ethernet ordinaria. Así, es el conmutador quien se encarga de etiquetar las tramas y de retirar la etiqueta en su destino final. Un puerto de acceso puede recibir tramas etiquetadas, pero si éstas no corresponden con el PVID del puerto, éstas son descartadas. Puertos de trunking Como ya hemos mencionado, estos puertos pueden recibir y enviar tramas etiquetadas. Típicamente se utilizan para la interconexión entre conmutadores que soportan varias VLANs, así como para conectar dispositivos (servidores) que pertenecen a varias VLAN y que tienen la capacidad de gestionar el etiquetado de VLANs. Estos puertos pertenecen a varias VLANs y sólo aceptarán tramas con los identficadores correspondientes. Existe un tercer tipo de puerto llamado híbrido. Normalmente opera como un puerto de trunking, pero puede recibir tramas no etiquetadas a las que les añadirá una etiqueta con su PVID. En la práctica, se desaconseja utilizar puertos híbridos. 2.9 Problemas Problema 2.1 ¿Pueden configurarse los puertos de un concentrador en modo full-dúplex? Justifique brevemente. Problema 2.2 ¿Pueden configurarse los puertos de un conmutador en modo full-dúplex? Justifique brevemente. Problema 2.3 ¿Porqué y cómo se sincroniza una trama ethernet? Problema 2.4 En IEEE 802.3/Ethernet, se acota la distancia máxima de la red local. ¿Cuál es esa distancia en 10Base5? ¿Por qué, al utilizar puentes o conmutadores la distancia máxima puede incrementarse? Problema 2.5 ¿Cómo se determinan las direcciones de difusión en 802.3? Problema 2.6 Responda cierto o falso El throughput total en una ethernet conmutada debería ser mayor que en una basada en concentradores CSMA/CD es un componente crítico de las redes Ethernet en half y full-dúplex En una trama E1 cada bit dura 488 nano segundos En Aloha ranurado la probabilidad de colisión es mayor que en Aloha puro En 10Base5 los transceivers (vampiros) deben estar al menos a 2.5 metros de distancia La codificación Manchester garantiza la sincronización de bits La energía de un bit en 10Base2 se propaga básicamente la misma distancia que la energía de un bit en 10BaseT En 8b6T se reconocen tres niveles de voltaje Problema 2.7 ¿Para qué sirve el IFG en Ethernet? ¿Cuánto tiempo dura en una red a 1 Gb/s? ( \\(96\\,ms\\);  \\(120\\,ms\\);  \\(512\\,ms\\);  \\(96\\,\\mu s\\);  \\(120\\,\\mu s\\);  \\(512\\,\\mu s\\);  \\(96\\,ns\\);  \\(120\\,ns\\);  \\(512\\,ns\\)) Problema 2.8 ¿Por qué en redes locales inalámbricas IEEE 802.11 el protocolo de control de acceso es CSMA/CA en vez de ser CSMA/CD como en IEEE 802.3? Problema 2.9 ¿Qué protocolo MAC se utiliza en IEEE 802.11g? Problema 2.10 Describa brevemente cómo es que los mecanismos RTS/CTS contribuyen a reducir drásticamente el problema de terminal oculta en 802.11. Notas IEEE también define un espacio de direcciones de ocho bytes bajo el formato EUI-64, pero éstas todavía son muy poco utilizadas. Los repetidores se encargan de tomar la señal por una de sus interfaces, regenerarla, amplificarla y reenviarla por las demás pero sí en la especificación de Ethernet original Es decir, la señal no está modulada: se transmite en exclusividad con la técnica de codificación apropiada - Manchester en este caso. Las categorías entre los distintos tipos de cable UTP tienen varias diferencias; una de las más notables, es que una categoría superior tiene mayor inmunidad a la interferencia. Entre las categorías 3 y 5 esto se consigue con un mayor número de vueltas por metro, lo que provoca una mejor cancelación de la radiación en cada par de hilos. Como veremos más adelante, se recomienda fragmentar una red con VLANs o subredes para no tener tantos nodos. Sin embargo, en la actualidad, con el surgimiento de dispositivos móviles y objetos inteligentes, es muy factible volver a tener redes lcoales con miles de dispositivos En realidad, es posible y relativamente sencillo usurpar una dirección MAC; la seguridad proporcionada por esta membresía depende en parte del cuidado que se tenga en impedir o dificultar que un hacker pueda conocer las direcciones MAC de equipos sensibles. "],["capa-de-red.html", "Capítulo 3 Capa de Red 3.1 Introducción 3.2 Protocolo IP 3.3 Esquema de direccionamiento 3.4 Protocolos auxiliares 3.5 IPv6 3.6 Enrutamiento", " Capítulo 3 Capa de Red 3.1 Introducción Como se ha mencionado al introducir el modelo de capas ISO/OSI, la función principal de la capa de red es encontrar una trayectoria por la cual se encaminarán los paquetes desde la fuente hasta su destino. A partir de este capítulo nos enfocaremos exclusivamente en las capas y protocolos del Modelo TCP/IP. En este modelo, la capa de red es, precisamente, la capa IP (Internet Protocol). En esta capa, a las unidades de información intercambiadas se les llama paquetes o datagramas. En el presente capítulo conoceremos el formato de los datagramas IPv4 e IPv6, así como algunos protocolos auxiliares como ICMP y ARP. También conoceremos los fundamentos para asignar direcciones a nuestras redes, subredes y equipos terminales. Finalmente, se presentarán distintos protocolos de enrutamiento, que son los que permiten encaminar o enrutar los paquetes desde la fuente hasta su destino. 3.2 Protocolo IP El éxito de Internet se explica en gran medida por determinadas decisiones fundamentales con las que fue diseñada (Saltzer, et al., 1984). Su objetivo primordial es interconectar redes heterogéneas entre sí (de ahí su nombre) de manera sencilla. Para ello, todos los dispositivos conectados deben hablar y entender un lenguaje común: el protocolo IP. El protocolo IP recibe información de la capa superior (la capa de transporte) y crea un datagrama que viaja por la red hasta su destino. Cuenta con un mecanismo sencillo para detectar errores en el encabezado. No verifica la integridad de la información pues esta función ya se realiza en capa de transporte (como se verá en el siguiente capítulo) o en la capa de enlace de datos. Existen dos versiones del protocolo IP: IPv4 e IPv6. En esta sección se presenta el protocolo IPv4. Mostraremos la operación de este protocolo a partir de la descripción de los campos que conforman el datagrama IP, el cual se presenta en la figura 3.1. Figura 3.1: Formato del datagrama IPv4 Versión. El primer campo, de cuatro bits, contiene la versión del datagrama. Sólo son válidos dos números: 0100 (versión 4) y 0110 (Versión 6). Hasta hoy, IHL. Internet Header Length. Dado que los datagramas IPv4 pueden contener opciones, la longitud del encabezado puede variar. Este campo contiene la longitud en múltiplos de 4 bytes (o en palabras de 32 bits). En realidad, es muy raro encontrar datagramas IP con opciones, por lo que este campo casi siempre contendrá el valor 5, que corresponde a 20 bytes, la longitud del encabezado sin opciones. DSCP. DiffServ Code Point Anteriormente este campo se conocía como Tipo de Servicio y tenía por intención permitir que el usuario pudiera indicar su preferencia por algún tipo de red en particular: baja latencia, alto caudal, servicio confiable o bajo costo. En la práctica, la preferencia casi nunca se especificaba y no se podía garantizar el servicio a lo largo de toda la internet. Lo que es peor, podía introducir lazos indeseables en el encaminamiento de paquetes. En la actualidad, este byte permite ofrecer servicios diferenciados cuando se implementa una red con distintas calidades de servicio. Longitud total. Indica la longitud total del datagrama. Dado que este campo es de 16 bits, la longitud total es de 64 kBytes (\\(2^{16}\\)). Identificación, Banderas y Offset del fragmento. Si bien el datagrama puede tener una longitud de hasta 64 kBytes, la realidad es que la mayoría de las redes pueden transportar paquetes de mucho menor tamaño. Por ejemplo, en el capítulo anterior se ha señalado que el tamaño máximo de una trama es de 1,500 bytes. En estos casos, el datagrama debe fragmentarse y los fragmentos viajan separados por la red hasta el destino, en el que se reunifican para formar el datagrama original. El datagrama original tiene un Identificador de 32 bits que se copia en todos los fragmentos. Todos los fragmentos, excepto el último, tienen la bandera M (More fragments) activado. La posición del fragmento en el datagrama original está indicada por el campo Offset del fragmento (en realidad es el valor indicado, multiplicado por 8). Como este proceso de fragmentación y rensamblado es muy costoso, si la bandera D (Dont fragment) está encendida, significa que se prefiere descartar el datagrama que fragmentarlo. Tiempo de vida. Indica el número máximo de saltos que puede tomar un datagrama antes de ser descartado. El valor actual de default es de 32. Cada vez que el paquete llega a un enrutador, este valor se decrementa en uno. Si llega a cero, el enrutador lo descarta y, opcionalmente, envía un mensaje indicando que el destinatario fue inalcanzable. Esta es una forma sencilla de eliminar datagramas que, por ejemplo, tienen algún error en su dirección destino y que podrían estar viajando por la red de manera indefinida Como se verá más adelante, cuando un enrutador no conoce la trayectoria para acercar el datagrama a su destino, suele enviarlo a una ruta por omisión. Si todos los enrutadores tienen una ruta por omisión, el paquete estaría viajando indefinidamente por la red. Protocolo. Indica el protocolo superior (o de la capa de red) al cual se le debe de entregar la información que transporta el datagrama. La lista de protocolos está especificada en el RFC 1700. Checksum. Se calcula como el complemento a 1 de la suma de 16 bits de los campos del encabezado. Aunque débil, es un mecanismo que no requiere de mucho procesamiento, lo cual es importante porque cada enrutador lo debe calcular. Se asume que la información está protegida con algoritmos más robustos en la capa 4 y, como se ha mostrado, en la capa 2. Dirección fuente y destino. Indican el número de red y el número de nodo para el emisor y receptor del paquete, respectivamente. En la siguiente sección se presentan las direcciones IP detalladamente. Opciones. Inician con un byte que identifica el código de la opción. Se han especificado opciones para seguridad, enrutamiento estricto, registro de rutas y sellos de tiempo, entre otros. La realidad es que las opciones prácticamente nunca se utilizan (de hecho, fueron descartadas en la especificación de IPv6) y no serán cubiertas en estas notas. Padding. El encabezado de IP debe ser un múltiplo de 4 bytes (palabras de 32 bits). Si se incluye una opción que no sea múltiplo de 4 bytes, en este campo se añade un relleno para alinearla a esa longitud. 3.3 Esquema de direccionamiento Para comunicarse, cada dispositivo necesita de un identificador único17 llamado la dirección IP. Para entender el formato de las direcciones IP, un concepto esencial que debe quedar muy claro, es que Internet es una * Interconexión de Networks *. Por ello, las direcciones IP están formadas por dos partes: un identificador de red y un identificador de host o dispositivo (en realidad, un identificador de la tarjeta de red del dispositivo). Como se observa en la figura 3.1, cada datagrama contiene la dirección del destinatario. Los nodos de conmutación en la red, llamados enrutadores en esta capa, revisan la parte de red de la dirección IP y deciden a qué enrutador vecino entregarle el datagrama para acercarlo a la red donde se encuentra el destinatario. Una vez alcanzada la red destino, se analiza la parte de host de la dirección IP para entregarla al dispositivo correspondiente. En IPv4, las direcciones IP son de 32 bits y, para simplificar su interpretación por las personas, son divididas en cuatro bytes, cada uno expresado en formato decimal y separado por un punto. Por ejemplo, la computadora que hospeda el servidor Web del ITAM, tiene la dirección IP 148.205.148.6, lo cual es mucho más sencillo de asimilar, que su equivalente en binario: 10010100 11001101 10010100 0000110. 3.3.1 Clases de direcciones IP Cada red conectada a Internet debe tener su propia dirección (su identificador único) y los enrutadores debían contar con un mecanismo sencillo para poder obtener ese identificador de la dirección IP y, con base en él, encaminar el datagrama hacia la red donde se encuentra el destinatario. Para ello, los diseñadores de Internet decidieron definir cinco distintos tipos de redes que se pueden distinguir a partir de los bits más significativos de la dirección IP. Clase A Si el bit más significativo de la dirección IP empieza en cero, tenemos una direción clase A y el primer byte de la dirección IP es el identificador de la red. Los tres bytes restantes quedan disponibles para identificadores de hosts en esa red. Con siete bits (recordemos que el primer bit ya se ocupó, debe ser cero), tenemos \\(2^7=128\\) identificadores de red clase A. En realidad, 126, pues los identificadores 0 y 127 están reservados. Cada una de estas redes dispone de \\(2^{24}-2=16,777,214\\) identificadores de host. Se han reducido dos direcciones pues cuando todos los bits de la parte de host están en cero, tenemos el identificador de la red y cuando todos están en uno, tenemos una dirección de difusión dentro de esa red. Esta clase fue propuesta para muy pocas grandes organizaciones con una gran cantidad de hosts, como puede ser un organismo de gobierno o un proveedor de acceso a Internet. Clase B Si el bit más significativo de la dirección IP empieza en uno y el siguiente en cero, tenemos una direción clase B y los dos primeros bytes son el identificador de la red. Los dos bytes restantes quedan disponibles para identificadores de hosts en esa red. Con 14 bits (los primeros dos valen 10), tenemos \\(2^{14}=16,384\\) identificadores de red clase B. Cada una de estas redes dispone de \\(2^{16}-2=64,534\\) identificadores de host. Esta clase fue propuesta para organizaciones de tamaño medio y grande que pudieran tener unos miles de computadoras conectadas a Internet. Observe que sólo hay 16,384 de estas direcciones disponibles en el mundo. El ITAM tiene una de ellas. Clase C Si los dos primeros bits más significativos de la dirección IP empiezan en uno y el tercero en cero, tenemos una direción clase C y los tres primeros bytes de la dirección IP son el identificador de la red. El byte restante queda disponible para identificadores de hosts en esa red. Con 21 bits (los 3 primeros valen 110), tenemos \\(2^{21}=2,097,152\\) identificadores de red clase C. Cada una de estas redes dispone de \\(2^{8}-2=254\\) identificadores de host. Esta clase fue propuesta para organizaciones con pocas computadoras con necesidad de conectarse a Internet. Se anticipaba que hubiera unos pocos millones de organizaciones de este tipo. Recordemos que estas decisiones se tomaron hace más 40 años, cuando nadie imaginaba lo que terminó siendo Internet en nuestras vidas. Clase D Las direcciones clase D se reconocen porque los primeros cuatro bits más significativos tienen un valor 1110. Con ellas se pueden crear grupos Multicast, en los que el datagrama se entrega a todos los dispositivos que tengan la misma dirección IP multicast. Por ejemplo, en algunos de los protocolos de enrutamiento que se verán más adelante, los enrutadores se configuran con direcciones multicast para que sólo ellos reciban los datagramas con la información que les permita concebir la topología de la red. Clase E Si los primeros cuatro bits valen uno, se tiene una dirección clase E. Se trata de un bloque reservado para experimentación y sus direcciones no pueden ser utilizadas en una red operativa. En la tabla de la figura 3.2 se sintetizan las principales características de las clases de direcciones IP: Figura 3.2: Clases de direcciones IP 3.3.2 Subredes IP y Enmascaramiento No es práctico tener un espacio plano de direccionamiento para todos los dispositivos en una red. No tiene mucho sentido enumerar de manera consecutiva a cada uno de los dispositivos pues con toda probabilidad estos dispositivos podrían organizarse en grupos, por ejemplo, con base en su ubicación o su función en la organización, tal como se podrían organizar las VLANs. Una red IP puede dividirse en pequeñas redes llamadas subredes. Para identificar cada una de las subredes, se toman prestados bits del campo de host de la dirección IP. Entonces, en la dirección IP se tiene un campo para identificar la red, un campo para identificar las subredes en esa red y un campo para identificar los dispositivos en cada subred. Ejemplo 3.1 Supongamos una organización que tiene una dirección de clase B con la que puede asignar direcciones IP a 65,534 dispositivos. Si la organización tiene 12 unidades de negocio, entonces podría definir doce subredes (en realidad, 16) y en cada una de estas subredes podría asignar direcciones para poco más de 4,000 dispositivos. Dado que se tienen que definir 12 subredes, se deben tomar prestados cuatro bits del campo de host (\\(2^3 = 8 &lt; 12 \\le 2^4=16\\)) y quedan 12 bits para asignar direcciones IP a dispositivos en cada subred. Las subredes están bajo administración local, por lo que el mundo externo ve a la organización como una sola red sin tener conocimiento detallado de su estructura interna. En cambio, los enrutadores dentro de la organización deben saber a qué subred dirigir el tráfico correspondiente, es decir cuántos bits de la dirección IP contienen la dirección de red y subred. Para ello se utilizan las máscaras de red. Al igual que las direcciones IP, la máscara de red también tiene una longitud de 32 bits y se expresa como cuatro dígitos decimales. Los bits en 1 en la máscara indican los bits correspondientes en la dirección IP que identifican las direcciones de red y subred (no se hace distinción entre ellas, no es necesario). Los bits en 0 en la máscara, indican los bits correspondientes en la dirección IP que identifican las direcciones de los hosts. Para la red del ejemplo 3.1, la máscara tiene los primeros 20 bits encendidos y su identificador es `255.255.240.0 como se muestra en la figura 3.3. Figura 3.3: Subredes y máscara de red 3.3.3 Direccionamiento Para reforzar los conceptos de redes, subredes y máscaras, hagamos un ejercicio de direccionamiento. Considere la red de la figura 3.4 que tiene una dirección clase C 198.62.193.0. Nuestro trabajo es asignar direcciones IP dentro de ese bloque a todos los dispositivos en la red. Figura 3.4: Red para ejemplo de direccionamiento En primer lugar, se debe identificar cuántas subredes y cuántos dispositivos en cada subred se conectarán. Esto determina cómo se hará el direccionamiento. Para nuestro ejercicio, vamos a considerar que en ninguna subred habrá más de 10 dispositivos. ¿Cuántas subredes tiene la red de la figura 3.4? Con poca experiencia diríamos que hay cuatro subredes. Sin embargo, si recordamos que los enrutadores separan (e interconectan) redes (ok, también subredes), en realidad tenemos siete. Las cuatro en los extremos y las tres que las interconectan. A pesar de ser enlaces punto a punto, en Internet son consideradas redes. Si tenemos siete subredes, debemos tomar prestados 3 bits del campo de host, dejando 5 bits para poder direccionar hasta 30 dispositivos en cada subred. Sin embargo, esto no deja ningún margen para añadir más subredes. Dado que en ninguna red habrá más de 10 dispositivos, el campo de host debe ser de cuatro bits, lo que nos deja cuatro bits para los identificadores de subred, con lo que podremos definir en un futuro hasta 16 subredes. Con esa política de direccionamiento, en la figura 3.5 se muestran los primeros ocho identificadores de subred para nuestro ejercicio. Figura 3.5: Identificadores de subred para la red del ejemplo. Es momento de asignar identificadores a (las interfaces de) los dispositivos. Podríamos asignarlos de manera arbitraria, pero siempre es una buena práctica que simplifica la gestión de la red, establecer una política. Por ejemplo, el gateway en la red tendrá el identificador menos significativo, el servidor de configuración DHCP el siguiente, el servidor de impresión el siguiente, y las computadoras de los usuarios se asignan consecutivamente en orden descendente. Con una política como la anterior, y recordando que las direcciones primera y última están reservadas, la asignación de direcciones en la red de nuestro ejemplo quedaría como se muestra en la figura 3.6. Figura 3.6: Red de ejemplo con direcciones asignadas. 3.3.4 Máscaras de longitud variable El ejercicio de direccionamiento que acabamos de realizar, cumple con lo necesario para ese ejemplo pero es ineficiente. En particular, sabemos que en los enlaces punto a punto que interconectan las subredes, no habrá dispositivos de usuarios. Sin embargo, para cada uno de esos enlaces (de esas subredes) se ha reservado un bloque con 14 direcciones de host, de las que únicamente se utilizan dos. Las otras 12 se están desperdiciando. Esto puede resolverse utilizando máscaras de longitud variable (VLSM) que permiten optimizar el espacio de direcciones disponibles mediante la división de una red (o subred) en subredes de diferente tamaño. En otras palabras, dentro de la organización es válido y hasta recomendable, utilizar máscaras con diferentes longitudes en distintas subredes, atendiendo las necesidades reales de direccionamiento de la organización. En nuestro ejercicio, los enlaces punto a punto requieren únicamente de dos direcciones, una para cada interfaz de red18. Para obtener dos direcciones IP, necesitamos de dos bits del campo de host. Esto nos da cuatro identificadores, pero recordemos que el primero y el último están reservados. Entonces, para los identificadores de las subredes de los enlaces punto a punto, podemos extender la máscara de 28 a 30 bits a partir del identificador de (sub)red 198.62.193.64. El direccionamiento resultante se muestra en la figura 3.7. Figura 3.7: Direccionamiento con máscaras de longitud variable. 3.3.5 CIDR A principios de los años 90 se pusieron en evidencia varios problemas relacionados con el direccionamiento basado en clases de redes y que estaba acelerando el agotamiento de las direcciones IP disponibles. Considere el caso de una organización que requiere de 1,800 direcciones IP para sus dispositivos. En los años 80, se le hubiera otorgado una dirección clase B, desperdiciando ¡63,734 direcciones! Otra opción podría ser asignarle ocho direcciones clase C; el desperdicio sería menor pero la organización debe anunciar y atender los paquetes dirigidos a esas ocho redes. Esto aumenta innecesariamente las tablas de enrutamiento en Internet. CIDR, Classless Inter-Domain Routing se desarrolló a principios de la década de 1990 para atender estos problemas. La idea es básicamente utilizar únicamente la máscara de red para establecer qué bits conforman el identificador de red en vez de observar únicamente los primeros bits más significativos. A los n bits que conforman la máscara se le llama prefijo y determinan el identificador de red de la dirección IP. Se representa con una diagonal y el número de bits correspondiente. Por ejemplo, la máscara 255.255.0.0 se representa con el prefijo /16. Con esta técnica, los bloques de direcciones IP se pueden asignar de manera más flexible y eficiente pues CIDR permite que los bloques de direcciones sean asignados con una longitud de prefijo variable, lo que significa que una red puede recibir una cantidad más ajustada de direcciones, evitando así el desperdicio de espacio de direcciones. En el ejemplo anterior, ahora se podría asignar a la organización que requiere de 1,800 direcciones IP, el bloque 192.168.0.0/21, lo que deja un espacio de 2,046 direcciones de host. CIDR se convirtió en una solución esencial para paliar el agotamiento de las direcciones IPv4, y sigue siendo ampliamente utilizado en la actualidad junto con la adopción creciente de IPv6, que ofrece una cantidad significativamente mayor de direcciones. Al introducir CIDR también se restringió severamente el otorgamiento de direcciones de red. En la mayoría de los países, estas direcciones únicamente se otorgan a proveedores de acceso a Internet (ISP) con base en los siguientes bloques de direcciones que se reservaron para la distintas regiones geográficas: Bloque Región 192.0.0 a 193.255.255 Multiregión 194.0.0 a 195.255.255 Europa 196.0.0 a 197.255.255 Otros 198.0.0 a 198.255.255 América del Norte 200.0.0 a 201.255.255 America Central y del Sur 202.0.0 a 203.255.255 Costa del Pacífico 204.0.0 a 205.255.255 Otros 206.0.0 a 207.255.255 Otros Sumarización de direcciones Como se ha comentado, CIDR también permite que las tablas de enrutamiento sean menores y se actualicen con menor frecuencia, lo que mejora el desempeño de los enrutadores. En efecto, si los bloques de direcciones se asignan a regiones, los administradores de las regiones a ISPs y los ISPs a sus clientes, entonces es posible anunciar en la Internet el prefijo de un ISP sin tener que anunciar todas las redes que administra ese ISP. Cuando un paquete llega al ISP, éste utilizará un prefijo más grande para encaminarlo a la red del cliente que corresponda. Esta forma de enrutamiento jerárquico es lo que se conoce como sumarización de rutas. La red de la figura 3.8 ejemplifica este concepto. El núcleo es la red de un ISP que tiene dos clientes: A1, al que le asignó las redes 100.20.0.0 a 200.20.0.15, y A2 al que le asignó las redes 200.20.16.0 a 200.20.16.31. Figura 3.8: Ejemplo de sumarización de direcciones. En vez de anunciar a Internet las 32 redes, el ISP anunciaría únicamente una red con el prefijo 200.20.0.0/19. Para poder realizar la agregación es necesario que el número de redes sea una potencia de 2 y que todas ellas compartan los bits que se encuentran más a la izquierda, es decir, que tengan el mismo prefijo. Por ejemplo, las 8 redes clase C 192.168.168.0 a 192.168.175.0 pueden agregarse en 192.168.168.0/21. 3.3.6 Asignación de direcciones a dispositivos La asignación de direcciones a dispositivos en una red es un aspecto fundamental para asegurar la conectividad y el funcionamiento adecuado de los sistemas. Existen dos métodos principales para llevar a cabo esta asignación: la configuración manual y la configuración dinámica a través de protocolos como RARP, BOOTP y DHCP. En la configuración manual, un administrador de red asigna manualmente una dirección IP específica a cada dispositivo en la red. Esta asignación se realiza de forma estática y permanente, lo que significa que la dirección IP del dispositivo no cambia a menos que el administrador realice una modificación. Si bien la configuración manual ofrece precisión y control sobre las direcciones IP asignadas, puede resultar tediosa y propensa a errores en redes con muchos dispositivos. Esta configuración sólo es recomendable dispositivos que requieren de una dirección IP estable, como es el caso de servidores y enrutadores por omisión. La configuración dinámica se basa en la automatización de la asignación de direcciones IP mediante protocolos como RARP (Reverse Address Resolution Protocol), BOOTP (Bootstrap Protocol) y DHCP (Dynamic Host Configuration Protocol). RARP permite que un dispositivo sin dirección IP conozca su dirección IP a partir de su dirección física (MAC address). BOOTP fue el precursor de DHCP y se utilizaba para proporcionar direcciones IP y otra información de configuración básica a los dispositivos durante el arranque. DHCP es el protocolo más utilizado actualmente para asignar direcciones IP de manera dinámica y automática a los dispositivos en una red. Con DHCP, los dispositivos pueden obtener una dirección IP temporalmente cuando se conectan a la red, lo que facilita la gestión y la flexibilidad en entornos con dispositivos móviles o una alta rotación de dispositivos. El servidor DHCP también configura en el cliente otros parámetros importantes como el prefijo o máscara de red, la dirección de los DNS (se verán más adelante) y de los enrutadores por omisión. Veamos el funcionamiento del protocolo DHCP a partir de la siguiente tabla de estados: Estado Descripción Descubrimiento El cliente DHCP envía un paquete discover a la red local para encontrar un servidor DHCP. La dirección de difusión es 255.255.255.255 Oferta Todos los servidores DHCP que escuchan el mensaje anterior responden al cliente con una mensaje offer de dirección IP y configuración de red. Solicitud El cliente selecciona una de las ofertas y envía una solicitud para aceptar la oferta de un servidor DHCP específico mediante un mensaje request Aceptación El servidor DHCP confirma la solicitud del cliente con un mensaje Ack y asigna la dirección IP definitiva al cliente. Renovación Durante el tiempo de arrendamiento, el cliente DHCP renueva la dirección IP con el servidor DHCP. Reautenticación Cuando se alcanza la mitad del tiempo de arrendamiento, el cliente DHCP verifica la conexión. Liberación Cuando un dispositivo se desconecta o apaga, libera la dirección IP asignada y queda disponible. En realidad, se tienen tres modos de operación: Asignación manual, asignación dinámica permanente y asignación dinámica (leasing). En esta última, la dirección se asigna durante un período de tiempo y el cliente debe estar renovando continuamente la solicitud. Si por un lado DHCP simplifica la configuración y contribuye a la escalabilidad de la red, ciertas funciones administrativas pueden complicarse. Por ejemplo, si los dispositivos reciben dinámicamente su dirección, ¿cómo identificar cuál es el dispositivo que presenta una falla? 3.3.7 Direcciones privadas Con el crecimiento exponencial de Internet a principios de la década de los 90, CIDR no sería suficiente para frenar el agotamiento de direcciones IP, por lo que surgieron otras iniciativas. La más importante fue la creación del protocolo IPv6, que veremos más adelante. Pero la más efectiva hasta hoy, fue la definición de bloques de direcciones privadas. Las direcciones privadas son bloques de direcciones IP que pueden ser utilizadas dentro de las redes locales de una organización para poder aprovechar la pila de protocolos TCP/IP para interconectar dispositivos sin que éstos requieran de direcciones IP únicas y globales. Con una dirección privada se puede hacer prácticamente todo lo que se puede hacer con una dirección pública global, excepto interconectarse a Internet. La direcciones privadas no son ruteables en Internet, lo que significa que los dispositivos que utilizan direcciones IP privadas no pueden comunicarse directamente con dispositivos fuera de la red de la organización. Los bloques de direcciones IP privadas fueron definidos en el RFC 1918, publicado en 1996. Los tres rangos de direcciones IP privadas son los siguientes: 10.0.0.0 a 10.255.255.255 (rango CIDR: 10.0.0.0/8): Este bloque de direcciones privadas ofrece más de 16 millones de direcciones IP, lo que lo convierte en la opción preferida para redes empresariales y corporativas. 172.16.0.0 a 172.31.255.255 (rango CIDR: 172.16.0.0/12): Este bloque de direcciones privadas proporciona más de un millón de direcciones IP y suele ser utilizado en redes medianas o grandes. 192.168.0.0 a 192.168.255.255 (rango CIDR: 192.168.0.0/16): Este bloque de direcciones privadas ofrece aproximadamente 65 mil direcciones IP y es comúnmente utilizado en redes domésticas y PyMEs. Además de las direcciones privadas, existen otros bloques de direcciones IP que están reservados para fines específicos, como: Direcciones de lazo de retorno (loop local): 127.0.0.0 a 127.255.255.255 (rango CIDR: 127.0.0.0/8). Estas direcciones se utilizan para la comunicación interna del dispositivo consigo mismo. La dirección 127.0.0.1 es comúnmente conocida como localhost y se utiliza para probar el funcionamiento de la pila de protocolos de red. Direcciones de rango de enlace local: 169.254.0.0 a 169.254.255.255 (rango CIDR: 169.254.0.0/16). Estas direcciones son asignadas automáticamente por los dispositivos cuando no pueden obtener una dirección IP válida de un servidor DHCP. Se utilizan en situaciones en las que no hay un servidor DHCP disponible para asignar direcciones. Este bloque fue definido en el RFC 3927. El uso adecuado de direcciones privadas y bloques de direcciones reservados es fundamental para garantizar una gestión eficiente de las direcciones IP dentro de una red local y para evitar conflictos de direcciones al conectarse a Internet. Al comprender estos rangos y su propósito, los administradores de redes pueden diseñar y configurar redes de manera más efectiva y segura. La asignación de direcciones IP privadas es una práctica común que permite una gestión más sencilla de las direcciones dentro de la red. Además, al no ser ruteables en Internet, son intrínsicamente seguras, pues un dispositivo con una dirección privada no puede ser accedido desde el exterior de la organización. Network Address Translation - NAT Network Address Translation (NAT) es una técnica que permite que muchos dispositivos puedan compartir una o unas cuantas direcciones IP. Así, las redes de la organización pueden ser desplegadas con direcciones privadas y si algunos dispositivos necesitan acceder a Internet, pueden hacer uso temporal de las direcciones públicas a disposición de la organización. Ejemplo 3.2 Imaginemos que una organización dispone de las direcciones públicas 200.1.1.1 a 200.1.1.5 y tiene 100 dispositivos en su red interna con direcciones privadas del bloque 10.0.0.0/8 En un momento determinado, el dispositivo 10.1.2.3 desea comunicarse con un servidor 198.9.8.7 (que está en una red externa). El datagrama eventualmente llegará al enrutador que conecta la organización con su ISP, donde normalmente reside el NAT; éste intercepta el mensaje y sustituye la dirección fuente por una de su pool, digamos, 200.1.1.3. La respuesta del servidor llegará al NAT quien habrá registrado que la dirección 200.1.1.3 fue asignada al dispositivo 10.1.2.3 por lo que puede remplazar la dirección (ahora, de destino) por la del dispositivo. Mientras esa comunicación tiene lugar (las direcciones se asignan por un cierto tiempo o hasta que se cierra la conexión), otro dispositivo, digamos, 10.1.2.5 quiere comunicarse con el host 15.66.12.1. Al llegar al NAT, éste hará la sustitución de direcciones por otra disponible en el pool, por ejemplo, 200.1.1.1 para que el mensaje pueda viajar por Internet. Un problema evidente con el esquema anterior es que en un momento dado sólo podrían comunicarse hacia Internet tantos dispositivos como direcciones IP públicas tenga la organización. Esta es una seria restricción sobre todo en la actualidad, cuando el acceso a Internet es indispensable. Afortunadamente, es una restricción muy fácil de superar con una extensión de NAT llamada Network Address Port Translation (NAPT), o NAT con sobrecarga. Como se verá en capítulos posteriores, al punto de acceso al servicio de la capa de transporte en Internet, se le llama Puerto. Los paquetes que integran el flujo entre un emisor y un destinatario, pueden distinguirse por una tupla de cinco elementos: Dirección IP fuente; dirección IP destino; protocolo en la capa de transporte; puerto fuente y puerto destino. Tomando ventaja de lo anterior, NAPT mapea los paquetes de un emisor a un puerto fuente y una dirección IP pública. Como se tienen más de 60,000 puertos fuente, entonces se pueden tener muchísimas sesiones entre dispositivos con direcciones privadas y dispositivos en Internet, utilizando una única dirección IP pública. Ejemplo 3.3 Continuando con el ejemplo 3.2, ahora la organización dispone únicamente de la dirección pública 200.1.1.1. Cuando el dispositivo 10.1.2.3/2345 desea comunicarse con el servidor 198.9.8.7/80 (2345 es el puerto fuente asignado por el sistema operativo al proceso que desea la comunicación; 80 es le puerto del proceso en el destino; este puerto es para servidores Web) el datagrama es interceptado por el NAPT, quien sustituye la dirección fuente por la pública y el puerto fuente por uno que tenga disponible, digamos, 1024. La respuesta del servidor llegará al NAPT quien habrá registrado que el puerto 1024 fue asignada al flujo proveniente de 10.1.2.3/2345 por lo que puede remplazar la dirección y el puerto correspondientes. Mientras esa comunicación tiene lugar el flujo proveniente de 10.1.2.5/1234 quiere comunicarse con el host 15.66.12.1/80. Al llegar al NAPT, éste hará la sustitución con otro puerto que tenga disponible, por ejemplo, el 1025 Un NAT puede ser implementado en un enrutador, en un firewall o en un dispositivo especializado. Esta es la mejor opción para redes donde el trafico es elevado pues requiere mucho procesamiento: no solo deben cambiarse las direcciones sino debe recalcularse el CRC de los encabezados. Además, en algunos protocolos (eg, Comando PORT de ftp; H.323; DNS) también debe analizarse el campo de datos para detectar y modificar direcciones ahí y posiblemente hasta cambie de tamaño la trama. Normalmente NAT proporciona una traducción dinámica, aunque algunas implantaciones soportan asignación estática para servicios como WWW y mail servers. 3.4 Protocolos auxiliares 3.4.1 ICMP Definido en el RFC 792, ICMP (Internet Control Message Protocol) es un protocolo auxiliar esencial en las redes TCP/IP. se utiliza principalmente para proporcionar notificaciones sobre el funcionamiento de la red, así como para informar sobre errores y problemas en la transmisión de paquetes IP. ICMP va encapsulado en IP como si fuera un protocolo de alto nivel, sin embargo, se considera como parte integral del protocolo IP. ICMP reporta errores, mas no hace confiable a IP. La confiabilidad debe ser implementada por protocolos de alto nivel. A través de mensajes ICMP, los dispositivos pueden enviar solicitudes de eco (ping) para probar la conectividad y latencia con otros dispositivos. Además, ICMP también se utiliza para notificar errores, como la falta de una ruta adecuada para la entrega de un paquete IP, lo que resulta en mensajes de Tiempo Excedido o Destino Inalcanzable. A continuación se presentan los principales mensajes ICMP: Destino inalcanzable.- ICMP type: 3. El paquete no se entregó. No puede encontrarse la ruta o un paquete con el bit DF no puede pasar una red con un valor de paquete mas pequeño. Tiempo excedido.- ICMP type: 11. El valor de TTL llegó a 0 y el paquete ha sido descartado (posible condición de loop o tiempo de reensamble expirado). Problemas con parámetros.- ICMP type: 12. Un valor ilegal ha sido detectado en algún campo del encabezado. Anuncio y solicitud de enrutador.- ICMP type: 9,10. Permite a los enrutadores anunciarse en una subred o contestar a una solicitud, todo lo anterior con la finalidad de configurar en forma automática el ruteador por default (gateway). Redirección.- ICMP type: 5. Se utiliza para que el enrutador le notifique al emisor que existe una ruta más adecuada. Este comando puede ser utilizado maliciosamente, por lo que muchos enrutadores lo bloquean Petición y respuesta de eco.- ICMP type: 8, 0. Sirve para saber si un nodo es alcanzable y está activo. Son los comandos de la aplicación ping. Las dos aplicaciones de ICMP más ampliamente utilizadas basadas en los mensajes ICMP son: ping. Envía paquetes de solicitud de eco (type 8) a un host remoto y espera una respuesta de eco (type 0). Esto permite verificar si un host remoto está disponible y mide el tiempo de ida y vuelta (RTT) de los paquetes, lo que es útil para monitorear la conectividad y la latencia de la red. traceroute. Con ayuda del mensaje tiempo excedido (type 11), determina la ruta completa que un datagrama sigue desde el emisor hasta el destinatario. Envía un datagrama IP (UDP) al nodo destino con un TTL=1, el primer enrutador decrementa ese valor, descarta la trama y envía un mensaje ICMP de tiempo excedido. De esa forma el primer enrutador es localizado. Este proceso es repetido con valores de TTL incrementados en forma sucesiva. El UDP enviado hace referencia a un puerto (aplicación no existente), de tal forma que cuando dicho UDP alcanza al nodo destino, este contesta con un mensaje ICMP de puerto inalcanzable, de esa forma Traceroute determina cuando el nodo destino ha sido alcanzado. Aunque ICMP es de gran utilidad para monitorear y mantener el estado de la red, también puede ser utilizado maliciosamente en ataques de denegación de servicio (DoS) o para eludir la seguridad. Por esta razón, en algunos entornos, los administradores de red pueden limitar o filtrar ciertos tipos de mensajes ICMP para mejorar la seguridad. 3.4.2 ARP Como vimos en el capítulo anterior, la comunicación entre nodos dentro de una red local (o dominio de difusión) se realiza con base en las direcciones MAC, también llamadas direcciones físicas. Si la red local está interconectada con otras redes de la misma organización, entonces es una subred cuyos nodos son identificados y accedidos desde las otras redes, a través de direcciones IP (también llamadas direcciones lógicas). El protocolo Address Resolution Protocol, ARP, definido en el RFC 826, sirve para realizar el mapeo de direcciones IP a direcciones MAC dentro de una misma subred. Todos los dispositivos mantienen una tabla ARP, llamada cache ARP que relaciona direcciones físicas (MAC) y lógicas (IP). Cuando un dispositivo necesita comunicarse con otro en la misma red local, busca en su tabla ARP si conoce la dirección MAC del destino requerido. Si la encuentra, simplemente arma la trama con la dirección MAC correspondiente y la envía. Si no se encuentra en la tabla ARP, el dispositivo envía una solicitud de ARP (ARP request) en forma de paquete de difusión preguntando por la dirección MAC del dispositivo con la dirección IP de destino como se muestra en la figura 3.9, donde se solicita la dirección MAC del dispositivo con dirección IP \\(IP_{1.2}\\). Figura 3.9: Envío de mensaje de difusión ARP Request. Como el mensaje fue enviado con una dirección de difusión, todos los dispositivos en la red local reciben la solicitud, pero solo el dispositivo con la dirección IP solicitada responde con un mensaje de respuesta de ARP (ARP reply) que contiene su dirección MAC (figura 3.10). Observe que esta es una respuesta unicast que solo va dirigida a quien emitió la solicitud ARP. Figura 3.10: Envío de mensaje ARP Reply. Una vez que el dispositivo solicitante recibe la respuesta, actualiza su tabla ARP con la dirección MAC del dispositivo de destino y utiliza esa dirección para comunicarse con el dispositivo en cuestión como se muestra en la figura 3.11. Figura 3.11: Comunicación con base en información de la tabla ARP. Cada entrada en la tabla ARP tiene un tiempo de vida, el cual se reinicializa mientras se observe actividad entre los dispositivos emisor y destinatario. El Protocolo ARP no tiene mecanismos de autenticación, lo que lo hace susceptible a ataques de suplantación o ARP spoofing. En este tipo de ataques, un dispositivo malicioso envía respuestas de ARP falsas para envenenar la tabla ARP de otros dispositivos y redirigir el tráfico hacia él. Para mitigar este riesgo, se han desarrollado técnicas de seguridad como el ARP cache poisoning detection (ARPWatch) y el uso de VLANs para segmentar la red. En algunas configuraciones de red, un enrutador puede actuar como un proxy ARP respondiendo a solicitudes ARP en nombre de otros dispositivos en la red. Esto permite que dispositivos en diferentes subredes se comuniquen entre sí sin la necesidad de que tengan conocimiento directo de las direcciones MAC del otro. Un dispositivo puede enviar un paquete de ARP gratuito para anunciar su dirección MAC en la red. Esto se utiliza a veces para actualizar la tabla ARP de otros dispositivos o para verificar si una dirección IP específica ya está siendo utilizada por otro dispositivo. 3.5 IPv6 Las direcciones IP utilizadas en la actualidad, tienen una longitud de 32 bits, con lo que, en principio, se podrían asignar más de 4 mil millones de identificadores únicos; un número bastante significativo para la época en que fue definido el protocolo IP. Sin embargo, debido a las políticas iniciales de asignación de direcciones y al totalmente inesperado crecimiento de la red, a principios de los años 90 se observó que las direcciones IP podrían agotarse muy rápidamente. La comunidad reaccionó con varias propuestas, entre las que cabe destacar a) una política mucho más restrictiva de asignación de direcciones; b) la definición y uso de bloques de direcciones privadas para ser utilizadas al interior de las organizaciones, junto con un esquema dinámico de traducción a direcciones públicas para aquellos flujos que debían atravesar la Internet; c) la definición de una nueva versión del protocolo de red, IPv6. IPv6 ofrece un espacio de direcciones varios órdenes de magnitud mayor al disponible actualmente. La longitud de una dirección es de 128 bits, que de acuerdo a algunas estimaciones pesimistas, permite contar con más de 1,500 direcciones únicas por metro cuadrado de la superficie terrestre (Hinden, 1995). Desafortunadamente, IPv6 no es compatible con su predecesor, por lo que su despliegue requiere de mecanismos para la coexistencia temporal de ambos protocolos, lo que se traduce en mayores costos de mantenimiento y gestión. Esto, aunado al hecho de que en los Estados Unidos el problema de agotamiento de direcciones no es tan grave, ha provocad que el despliegue de IPv6 sea particularmente lento en ese país, a diferencia de países como Corea y Japón, donde ha adquirido una atención especial. En 2005 el Gobierno estadounidense decretó un plazo de tres años para que todos sus productos de TI fueran compatibles con IPv6, por lo que se espera un estímulo importante en la adopción del protocolo en el sector privado en ese país (Garreston, 2005). 3.6 Enrutamiento 3.6.1 Enrutamiento estático 3.6.2 Enrutamiento dinámico- Vector de distancias 3.6.3 Enrutamiento dinámico - Estado de enlace 3.6.4 Enrutamiento externo "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
